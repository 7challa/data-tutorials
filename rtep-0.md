# Real time Data transportation and Ingestion



## <a id="h.7fhjo9i7tc76" name="h.7fhjo9i7tc76"></a>Introduction:

Welcome to a three part tutorial series on real time data ingesting and analysis.  The speed of today's processing systems have moved from classical data warehousing batch reporting to the realm of real-time processing and analytics. The result is real-time business intelligence. Real time means near to zero latency and access to information whenever it is required. This tutorial will show how geolocation information from trucks can be combined with sensor data from trucks and roads.  These sensors report real-time events like speeding, lane-departure, unsafe tailgating, and unsafe following distances. We will capture these events in real time.



## <a id="h.jcu889k9qsek" name="h.jcu889k9qsek"></a>Prerequisites:

*   Hortonworks Sandbox 2.3 up and running.
*   8GG+ RAM (Assigning more is recommended) and preferably 4 processor cores, otherwise you may encounter errors in the third tutorial
*   Data sets used:
  *   New York City Truck Routes from NYC DOT.
  *   Truck Events Data generated using a custom simulator.
  *   Weather Data, collected using APIs from Forcast.io.
  *   Traffic Data, collected using APIs from MapQuest.

All data sets used in these tutorials are real data sets but modified to fit these use cases



## <a id="h.aaet8ctgytv2" name="h.aaet8ctgytv2"></a>Tutorial Overview:

The events generated by sensors will be captured through a distributed publish-subscribe messaging system named Apache Kafka. We will use Apache Storm to process this data from Kafka and eventually persist that data into HDFS and Hbase.

## <a id="h.qkqvhtoi58t3" name="h.qkqvhtoi58t3"></a>Goals of the tutorial:

*   Understanding real time data analysis.
*   Understanding Apache Kafka architecture.
*   Creating Producers and Consumers in Kafka.
*   Understanding Apache Storm architecture.
*   Creating Spouts and Bolts in Storm.
*   Persisting data from Storm into Hive and Hbase

## <a id="h.6hkroym6o6f2" name="h.6hkroym6o6f2"></a>Outline:

1.  Tutorial Introduction
2.  Prerequisites:

1.  Data set used:
2.  Hortonworks Sandbox version: 2.3



1.  Tutorial Overview
2.  Goals of the Tutorial
3.  Concepts:

1.  [Apache Kafka](rtep-concepts.md)
2.  [Apache Storm](https://www.google.com/url?q=https://docs.google.com/document/d/1ta3jLQYwI6qtCBYrrNOJLFzD__2K9A7soVzJ_ozp65c/edit%23heading%3Dh.7s839ly49rfu&sa=D&ust=1452621795976000&usg=AFQjCNFONEO0Ee6xywl8IP9j6Us-4gFkhw)
3.  [Apache Storm on Kafka](https://www.google.com/url?q=https://docs.google.com/document/d/1SkabSpy6ZKNTam8uIOe5haM6faz5mgfmCwcOWXTruII/edit%23&sa=D&ust=1452621795977000&usg=AFQjCNF7zpIJM5znSUX5eNNMHpdnVvngWw)



1.  Get Started with HDP labs:

1.  Lab 1: Apache Kafka: Real time event stream transportation
2.  Lab 2: [Apache Storm: Processing real time event stream](https://www.google.com/url?q=https://docs.google.com/document/d/1P_MKDi0UBuqu5Sosb1G4fnGYvC1ShRUWL1Qdlpwatwk/edit%23heading%3Dh.2pah3dpfsgzn&sa=D&ust=1452621795979000&usg=AFQjCNES1bG670iOPKEKl-KVXRHi7sGmug)
3.  Lab 3: [Hive & Hbase: Persisting real time event stream](https://www.google.com/url?q=https://docs.google.com/document/d/13EKC0Vkxn9vxhoPCsRhxs8dGC0_kum-FsyoXMDdwsMM/edit%23heading%3Dh.stdzeyjgo1v8&sa=D&ust=1452621795980000&usg=AFQjCNGLMIVZcmPNgJq1RpuVXTYSXO3l7A)



1.  Next Steps/Try these
2.  References
