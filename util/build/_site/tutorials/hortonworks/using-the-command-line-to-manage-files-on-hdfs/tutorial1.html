

<div class="tutorial-content">
  <h1 id="manage-files-on-hdfs-with-the-command-line">Manage Files on HDFS with the Command Line</h1>

<h3 id="introduction">Introduction</h3>

<p>In this tutorial, we will walk through many of the common of the basic Hadoop Distributed File System (HDFS) commands you will need to manage files on HDFS. The particular datasets we will utilize to learn HDFS file management are San Francisco salaries from 2011-2014.</p>

<h2 id="pre-requisites">Pre-Requisites</h2>
<ul>
  <li>Downloaded and Installed latest <a href="http://hortonworks.com/products/hortonworks-sandbox/#install">Hortonworks Sandbox</a></li>
  <li>If you're planning to deploy your sandbox on Azure, refer to this tutorial: <a href="http://hortonworks.com/hadoop-tutorial/deploying-hortonworks-sandbox-on-microsoft-azure/">Deploying the Sandbox on Azure</a></li>
  <li><a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a></li>
  <li>Allow yourself around <strong>1 hour</strong> to complete this tutorial.</li>
</ul>

<h3 id="download-san-francisco-salary-related-datasets">Download San Francisco Salary Related Datasets</h3>

<p>We will download <strong>sf-salaries-2011-2013.csv</strong> and <strong>sf-salaries-2014.csv</strong> data onto our local filesystems of the sandbox. The commands are tailored for mac and linux users.</p>

<p>1. Open a terminal on your local machine, SSH into the sandbox:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ssh root@127.0.0.1 -p 2222
</code></pre>
</div>

<blockquote>
  <p>Note: If your on VMware or Azure, insert your appropriate ip address in place of 127.0.0.1. Azure users will need to replace port 2222 with 22.</p>
</blockquote>

<p>2. Copy and paste the commands to download the <strong>sf-salaries-2011-2013.csv</strong> and <strong>sf-salaries-2014.csv</strong> files. We will use them while we learn file management operations.</p>

<div class="highlighter-rouge"><pre class="highlight"><code># download sf-salaries-2011-2013
wget https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/using-the-command-line-to-manage-hdfs/sf-salary-datasets/sf-salaries-2011-2013.csv
# download sf-salaries-2014
wget https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/using-the-command-line-to-manage-hdfs/sf-salary-datasets/sf-salaries-2014.csv
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp-2.5/assets/using-the-command-line-to-manage-hdfs/sf_salary_datasets.png" alt="sf_salary_datasets" /></p>

<h2 id="outline">Outline</h2>
<ul>
  <li><a href="#create-a-directory-in-hdfs-upload-a-file-and-list-contents">Step 1: Create a Directory in HDFS, Upload a file and List Contents</a></li>
  <li><a href="#find-out-space-utilization-in-a-hdfs-directory">Step 2: Find Out Space Utilization in a HDFS Directory</a></li>
  <li><a href="#download-files-hdfs-to-local-file-system">Step 3: Download Files From HDFS to Local File System</a></li>
  <li><a href="#explore-two-advanced-features">Step 4: Explore Two Advanced Features</a></li>
  <li><a href="#use-help-command-access-hadoop-command-manual">Step 5: Use Help Command to access Hadoop Command Manual</a></li>
  <li><a href="#summary">Summary</a></li>
  <li><a href="#further-reading">Further Reading</a></li>
</ul>

<h3 id="step-1-create-a-directory-in-hdfs-upload-a-file-and-list-contents-">Step 1: Create a Directory in HDFS, Upload a file and List Contents <a id="create-a-directory-in-hdfs-upload-a-file-and-list-contents"></a></h3>

<p>Let's learn by writing the syntax. You will be able to copy and paste the following example commands into your terminal. Let's login under <strong>hdfs</strong> user, so we can give root user permission to perform file operations:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>su hdfs
cd
</code></pre>
</div>

<p>We will use the following command to run filesystem commands on the file system of hadoop:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hdfs dfs [command_operation]
</code></pre>
</div>

<blockquote>
  <p>Refer to the <a href="https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/FileSystemShell.html">File System Shell Guide</a> to view various command_operations.</p>
</blockquote>

<h3 id="hdfs-dfs--chmod">hdfs dfs -chmod:</h3>

<ul>
  <li>Affects the permissions of the folder or file. Controls who has read/write/execute privileges</li>
  <li>We will give root access to read and write to the user directory. Later we will perform an operation in which we send a file from our local filesystem to hdfs.</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>hdfs dfs -chmod 777 /user
</code></pre>
</div>

<ul>
  <li>Warning in production environments, setting the folder with the permissions above is not a good idea because anyone can read/write/execute files or folders.</li>
</ul>

<p>Type the following command, so we can switch back to the root user. We can perform the remaining file operations under the <strong>user</strong> folder since the permissions were changed.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>exit
</code></pre>
</div>

<h3 id="hdfs-dfs--mkdir">hdfs dfs -mkdir:</h3>

<ul>
  <li>Takes the path uri's as an argument and creates a directory or multiple directories.</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:
        # hdfs dfs -mkdir &lt;paths&gt;
# Example:
        hdfs dfs -mkdir /user/hadoop
        hdfs dfs -mkdir /user/hadoop/sf-salaries-2011-2013 /user/hadoop/sf-salaries /user/hadoop/sf-salaries-2014
</code></pre>
</div>

<h3 id="hdfs-dfs--put">hdfs dfs -put:</h3>

<ul>
  <li>Copies single src file or multiple src files from local file system to the Hadoop Distributed File System.</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:
        # hdfs dfs -put &lt;local-src&gt; ... &lt;HDFS_dest_path&gt;
# Example:
        hdfs dfs -put sf-salaries-2011-2013.csv /user/hadoop/sf-salaries-2011-2013/sf-salaries-2011-2013.csv
        hdfs dfs -put sf-salaries-2014.csv /user/hadoop/sf-salaries-2014/sf-salaries-2014.csv
</code></pre>
</div>

<h3 id="hdfs-dfs--ls">hdfs dfs -ls:</h3>

<ul>
  <li>Lists the contents of a directory</li>
  <li>For a file, returns stats of a file</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:  
        # hdfs dfs  -ls  &lt;args&gt;  
# Example:
        hdfs dfs -ls /user/hadoop
        hdfs dfs -ls /user/hadoop/sf-salaries-2011-2013
        hdfs dfs -ls /user/hadoop/sf-salaries-2011-2013/sf-salaries-2011-2013.csv
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp-2.5/assets/using-the-command-line-to-manage-hdfs/tutorial1/list_folder_contents.png" alt="list_folder_contents" /></p>

<h3 id="step-2-find-out-space-utilization-in-a-hdfs-directory-">Step 2: Find Out Space Utilization in a HDFS Directory <a id="find-out-space-utilization-in-a-hdfs-directory"></a></h3>

<h3 id="hdfs-dfs--du">hdfs dfs -du:</h3>

<ul>
  <li>Displays size of files and directories contained in the given directory or the size of a file if its just a file.</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:  
        # hdfs dfs -du URI
# Example:
        hdfs dfs -du  /user/hadoop/ /user/hadoop/sf-salaries-2011-2013/sf-salaries-2011-2013.csv
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp-2.5/assets/using-the-command-line-to-manage-hdfs/tutorial1/displays_entity_size.png" alt="displays_entity_size" /></p>

<h3 id="step-3-download-file-from-hdfs-to-local-file-system-">Step 3: Download File From HDFS to Local File System <a id="download-files-hdfs-to-local-file-system"></a></h3>

<h3 id="hdfs-dfs--get">hdfs dfs -get:</h3>

<ul>
  <li>Copies/Downloads files from HDFS to the local file system</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:
        # hdfs dfs -get &lt;hdfs_src&gt; &lt;localdst&gt;
# Example:
        hdfs dfs -get /user/hadoop/sf-salaries-2011-2013/sf-salaries-2011-2013.csv /home/
</code></pre>
</div>

<h3 id="step-4-explore-two-advanced-features-">Step 4: Explore Two Advanced Features <a id="explore-two-advanced-features"></a></h3>

<h3 id="hdfs-dfs--getmerge">hdfs dfs -getmerge</h3>

<ul>
  <li>Takes a source directory file or files as input and concatenates files in src into the local destination file.</li>
  <li>Concatenates files in the same directory or from multiple directories as long as we specify their location and outputs them to the local file system, as can be seen in the <strong>Usage</strong> below.</li>
  <li>Let's concatenate the san francisco salaries from two separate directory and output them to our local filesystem. Our result will be the salaries from 2014 are appended below the last row of 2011-2013.</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:
        # hdfs dfs -getmerge &lt;src&gt; &lt;localdst&gt; [addnl]
        # hdfs dfs -getmerge &lt;src1&gt; &lt;src2&gt; &lt;localdst&gt; [addnl]
# Option:
        # addnl: can be set to enable adding a newline on end of each file
# Example:
        hdfs dfs -getmerge /user/hadoop/sf-salaries-2011-2013/ /user/hadoop/sf-salaries-2014/ /root/output.csv
</code></pre>
</div>

<blockquote>
  <p>Merges the files in sf-salaries-2011-2013 and sf-salaries-2014 to output.csv in the root directory of the local filesystem. The first file contained about 120,000 rows and the second file contained almost 30,000 rows. This file operation is important because it will save you time from having to manually concatenate them.</p>
</blockquote>

<h3 id="hdfs-dfs--cp">hdfs dfs -cp:</h3>

<ul>
  <li>Copy file or directories recursively, all the directory's files and subdirectories to the bottom of the directory tree are copied.</li>
  <li>It is a tool used for large inter/intra-cluster copying</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># Usage:
        # hdfs dfs -cp &lt;src-url&gt; &lt;dest-url&gt;
# Example:
        hdfs dfs -cp /user/hadoop/sf-salaries-2011-2013/ /user/hadoop/sf-salaries-2014/ /user/hadoop/sf-salaries
</code></pre>
</div>

<blockquote>
  <p>-cp: copies sf-salaries-2011-2013, sf-salaries-2014 and all their contents to sf-salaries</p>
</blockquote>

<p>Verify the files or directories successfully copied to the destination folder:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hdfs dfs -ls /user/hadoop/sf-salaries/
hdfs dfs -ls /user/hadoop/sf-salaries/sf-salaries-2011-2013
hdfs dfs -ls /user/hadoop/sf-salaries/sf-salaries-2014
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp-2.5/assets/using-the-command-line-to-manage-hdfs/tutorial1/visual_result_of_cp.png" alt="visual_result_of_distcp" /></p>

<blockquote>
  <p>Visual result of distcp file operation. Notice that both src1 and src2 directories and their contents were copied to the dest directory.</p>
</blockquote>

<h3 id="step-5-use-help-command-to-access-hadoop-command-manual-">Step 5: Use Help Command to access Hadoop Command Manual <a id="use-help-command-access-hadoop-command-manual"></a></h3>

<p>Help command opens the list of commands supported by Hadoop Data File System (HDFS)</p>

<div class="highlighter-rouge"><pre class="highlight"><code># Example:  
        hdfs dfs  -help
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp-2.5/assets/using-the-command-line-to-manage-hdfs/tutorial1/help_command.png" alt="hadoop_help_command_manual" /></p>

<p>Hope this short tutorial was useful to get the basics of file management.</p>

<h2 id="summary-">Summary <a id="summary-lab1"></a></h2>
<p>Congratulations! We just learned to use commands to manage our <strong>sf-salaries-2011-2013.csv</strong> and <strong>sf-salaries-2014.csv</strong> dataset files in HDFS. We learned to create, upload and list the the contents in our directories. We also acquired the skills to download files from HDFS to our local file system and explored a few advanced features of HDFS file management using the command line.</p>

<h2 id="further-reading-">Further Reading <a id="further-reading"></a></h2>
<ul>
  <li><a href="http://hortonworks.com/hadoop/hdfs/">HDFS Overview</a></li>
  <li><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html">Hadoop File System Documentation</a></li>
</ul>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-120.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-120&topics=hdp-2.5.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Manage Files on HDFS with the Command Line</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-120</strong> and <strong>hdp-2.5.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
