

<div class="tutorial-content">
  <p>In this tutorial, we will learn to:</p>

<ul>
  <li>Configure Solr to store indexes in HDFS</li>
  <li>Create a solr cluster of 2 solr instances running on port 8983 and 8984</li>
  <li>Index documents in HDFS using the Hadoop connectors</li>
  <li>Use Solr to search documents</li>
</ul>

<h3 id="pre-requisitepre-requisite"><a href="#pre-requisite"></a>Pre-Requisite</h3>

<ul>
  <li><a href="http://hortonworks.com/sandbox">Hortonworks Sandbox</a></li>
</ul>

<h3 id="step-1---log-into-sandboxstep-1--log-into-sandbox"><a href="#step-1---log-into-sandbox"></a>Step 1 – Log into Sandbox</h3>

<ul>
  <li>
    <p>After it boots up, find the IP address of the VM and add an entry into your machines hosts file e.g.</p>

    <p>192.168.191.241 sandbox.hortonworks.com sandbox</p>
  </li>
  <li>
    <p>Connect to the VM via SSH (root/hadoop), correct the /etc/hosts entry</p>

    <p>ssh root@sandbox.hortonworks.com</p>
  </li>
  <li>
    <p>If running on an Ambari installed HDP 2.3 cluster (instead of sandbox), run the below to install HDPsearch</p>

    <p>yum install -y lucidworks-hdpsearch
sudo -u hdfs hadoop fs -mkdir /user/solr
sudo -u hdfs hadoop fs -chown solr /user/solr</p>
  </li>
  <li>
    <p>If running on HDP 2.3 sandbox, run below</p>

    <p>chown -R solr:solr /opt/lucidworks-hdpsearch</p>
  </li>
  <li>
    <p><strong>Run remaining steps as solr</strong></p>

    <p>su solr</p>
  </li>
</ul>

<h3 id="step-2---configure-solr-to-store-index-files-in-hdfsstep-2--configure-solr-to-store-index-files-in-hdfs"><a href="#step-2---configure-solr-to-store-index-files-in-hdfs"></a>Step 2 – Configure Solr to store index files in HDFS</h3>

<ul>
  <li>For the lab, we will use schemaless configuration that ships with Solr
    <ul>
      <li>Schemaless configuration is a set of SOLR features that allow one to index documents without pre-specifying the schema of indexed documents</li>
      <li>Sample schemaless configruation can be found in the directory /opt/lucidworks-hdpsearch/solr/server/solr/configsets/data_driven_schema_configs</li>
    </ul>
  </li>
  <li>
    <p>Let’s create a copy of the sample schemaless configuration and modify it to store indexes in HDFS</p>

    <div class="highlighter-rouge"><pre class="highlight"><code>cp -R /opt/lucidworks-hdpsearch/solr/server/solr/configsets/data_driven_schema_configs  /opt/lucidworks-hdpsearch/solr/server/solr/configsets/data_driven_schema_configs_hdfs 
</code></pre>
    </div>
  </li>
  <li>Open <code class="highlighter-rouge">/opt/lucidworks-hdpsearch/solr/server/solr/configsets/data_driven_schema_configs_hdfs/conf/solrconfig.xml</code> in your favorite editor and make the following changes:</li>
</ul>

<p>1- Replace the section:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>                &lt;directoryFactory name="DirectoryFactory"
                class="${solr.directoryFactory:solr.NRTCachingDirectoryFactory}"&gt;
                &lt;/directoryFactory&gt;
</code></pre>
</div>

<p><strong>with</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code>            &lt;directoryFactory name="DirectoryFactory" class="solr.HdfsDirectoryFactory"&gt;
                &lt;str name="solr.hdfs.home"&gt;hdfs://sandbox.hortonworks.com/user/solr&lt;/str&gt;
                &lt;bool name="solr.hdfs.blockcache.enabled"&gt;true&lt;/bool&gt;
                &lt;int name="solr.hdfs.blockcache.slab.count"&gt;1&lt;/int&gt;
                &lt;bool name="solr.hdfs.blockcache.direct.memory.allocation"&gt;false&lt;/bool&gt;
                &lt;int name="solr.hdfs.blockcache.blocksperbank"&gt;16384&lt;/int&gt;
                &lt;bool name="solr.hdfs.blockcache.read.enabled"&gt;true&lt;/bool&gt;
                &lt;bool name="solr.hdfs.blockcache.write.enabled"&gt;false&lt;/bool&gt;
                &lt;bool name="solr.hdfs.nrtcachingdirectory.enable"&gt;true&lt;/bool&gt;
                &lt;int name="solr.hdfs.nrtcachingdirectory.maxmergesizemb"&gt;16&lt;/int&gt;
                &lt;int name="solr.hdfs.nrtcachingdirectory.maxcachedmb"&gt;192&lt;/int&gt;
            &lt;/directoryFactory&gt;
</code></pre>
</div>

<p>2- set locktype to</p>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;lockType&gt;hdfs&lt;/lockType&gt;
</code></pre>
</div>

<p>3- Save and exit the file</p>

<h3 id="step-3---start-2-solr-instances-in-solrcloud-modestep-3--start-2-solr-instances-in-solrcloud-mode"><a href="#step-3---start-2-solr-instances-in-solrcloud-mode"></a>Step 3 – Start 2 Solr instances in solrcloud mode</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>mkdir -p ~/solr-cores/core1
mkdir -p ~/solr-cores/core2
cp /opt/lucidworks-hdpsearch/solr/server/solr/solr.xml ~/solr-cores/core1
cp /opt/lucidworks-hdpsearch/solr/server/solr/solr.xml ~/solr-cores/core2
/opt/lucidworks-hdpsearch/solr/bin/solr  start -cloud -p 8983 -z sandbox.hortonworks.com:2181 -s ~/solr-cores/core1
/opt/lucidworks-hdpsearch/solr/bin/solr  restart -cloud -p 8984 -z sandbox.hortonworks.com:2181 -s ~/solr-cores/core2
</code></pre>
</div>

<h3 id="step-4---create-a-solr-collection-named-labs-with-2-shards-and-a-replication-factor-of-2step-4--create-a-solr-collection-named-labs-with-2-shards-and-a-replication-factor-of-2"><a href="#step-4---create-a-solr-collection-named-labs-with-2-shards-and-a-replication-factor-of-2"></a>Step 4 – Create a Solr Collection named “labs” with 2 shards and a replication factor of 2</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/lucidworks-hdpsearch/solr/bin/solr create -c labs \
-d /opt/lucidworks-hdpsearch/solr/server/solr/configsets/data_driven_schema_configs_hdfs/conf -n labs -s 2 -rf 2
</code></pre>
</div>

<h3 id="step-5---validate-that-the-labs-collection-got-createdstep-5--validate-that-the-labs-collection-got-created"><a href="#step-5---validate-that-the-labs-collection-got-created"></a>Step 5 – Validate that the labs collection got created</h3>

<ul>
  <li>Using the browser, visit <a href="http://sandbox.hortonworks.com:8983/solr/#/%7Ecloud">http://sandbox.hortonworks.com:8983/solr/#/~cloud</a>. You should see the labs collection with 2 shards, each with a replication factor of 2.</li>
</ul>

<p><img src="/assets/search-with-solr/solrui.png" alt="Image" /></p>

<h3 id="step-6---load-documents-to-hdfsstep-6--load-documents-to-hdfs"><a href="#step-6---load-documents-to-hdfs"></a>Step 6 – Load documents to HDFS</h3>

<ul>
  <li>
    <p>Upload sample csv file to hdfs. We will index the file with Solr using the Solr Hadoop connectors</p>

    <p>hadoop fs -mkdir -p csv
hadoop fs -put /opt/lucidworks-hdpsearch/solr/example/exampledocs/books.csv csv/</p>
  </li>
</ul>

<h3 id="step-7---index-documents-with-solr-using-solr-hadoop-connectorstep-7--index-documents-with-solr-using-solr-hadoop-connector"><a href="#step-7---index-documents-with-solr-using-solr-hadoop-connector"></a>Step 7 – Index documents with Solr using Solr Hadoop Connector</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop jar /opt/lucidworks-hdpsearch/job/lucidworks-hadoop-job-2.0.3.jar com.lucidworks.hadoop.ingest.IngestJob -DcsvFieldMapping=0=id,1=cat,2=name,3=price,4=instock,5=author -DcsvFirstLineComment -DidField=id -DcsvDelimiter="," -Dlww.commit.on.close=true -cls com.lucidworks.hadoop.ingest.CSVIngestMapper -c labs -i csv/* -of com.lucidworks.hadoop.io.LWMapRedOutputFormat -zk localhost:2181
</code></pre>
</div>

<h3 id="step-8---search-indexed-documentsstep-8--search-indexed-documents"><a href="#step-8---search-indexed-documents"></a>Step 8 – Search indexed documents</h3>

<ul>
  <li>Search the indexed documents. Using the browser, visit the url <a href="http://sandbox.hortonworks.com:8984/solr/labs/select?q=*:*">http://sandbox.hortonworks.com:8984/solr/labs/select?q=<em>:</em></a></li>
  <li>You will see search results like below</li>
</ul>

<p><img src="/assets/search-with-solr/solr-query.png" alt="Image" /></p>

<h3 id="summarysummary"><a href="#summary"></a>Summary</h3>

<p>In this tutorial we have explored how to:</p>

<ul>
  <li>Store Solr indexes in HDFS</li>
  <li>Create a Solr Cluster</li>
  <li>Index documents in HDFS using Solr Hadoop connectors</li>
</ul>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-300.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-300&topics=hdp-2.4.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Searching Data with Solr</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-300</strong> and <strong>hdp-2.4.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
