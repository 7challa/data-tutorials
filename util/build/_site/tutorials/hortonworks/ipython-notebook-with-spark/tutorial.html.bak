

<div class="tutorial-content">
  <h3 id="introduction">Introduction</h3>

<p>In this tutorial, we are going to configure IPython notebook with Apache Spark on YARN in a few steps.</p>

<p>IPython notebook is an interactive Python shell which lets you interact with your data one step at a time and also perform simple visualizations.</p>

<p>IPython notebook supports tab autocompletion on class names, functions, methods, variables. It also offers more explicit and colour-highlighted error messages than the command line python shell. It provides integration with basic UNIX shell allowing you can run simple shell commands such as cp, ls, rm, cp, etc. directly from the IPython. IPython integrates with many common GUI modules like PyQt, PyGTK, tkinter as well wide variety of data science Python packages.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>This tutorial is a part of series of hands-on tutorials to get you started with HDP using Hortonworks sandbox. Please ensure you complete the prerequisites before proceeding with this tutorial.</p>

<ul>
  <li>Downloaded and Installed latest <a href="http://hortonworks.com/products/hortonworks-sandbox/#install">Hortonworks Sandbox</a></li>
  <li><a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a></li>
</ul>

<h3 id="installing-and-configuring-ipython">Installing and configuring IPython</h3>

<p>To begin, login in to Hortonworks Sandbox through SSH:The default password is <code class="highlighter-rouge">hadoop</code>.</p>

<p><img src="/assets/ipython-with-spark/saptek.png" alt="saptek" /></p>

<p>Now let’s configure the dependencies by typing in the following command:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>yum install nano centos-release-scl zlib-devel

yum install bzip2-devel openssl-devel ncurses-devel

yum install sqlite-devel readline-devel tk-devel

yum install gdbm-devel db4-devel libpcap-devel xz-devel

yum install libpng-devel libjpg-devel atlas-devel
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek2.png" alt="saptek2" /></p>

<p>IPython has a requirement for Python 2.7 or higher. So, let’s install the “Development tools” dependency for Python 2.7</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>yum groupinstall <span class="s2">"Development tools"</span>
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek3.png" alt="saptek3" /></p>

<p>Now we are ready to install Python 2.7.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>yum install python27
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek4.png" alt="saptek4" /></p>

<p>Now the Sandbox has multiple versions of Python, so we have to select which version of Python we want to use in this session. We will choose to use Python 2.7 in this session.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="nb">source</span> /opt/rh/python27/enable
</code></pre>
</div>

<p>Then we will download <code class="highlighter-rouge">easy_install</code> which we will use to configure <code class="highlighter-rouge">pip</code>, a Python package installer.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>wget https://bootstrap.pypa.io/ez_setup.py
</code></pre>
</div>

<p>Now let’s configure <code class="highlighter-rouge">easy_install</code> with the following command:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>python ez_setup.py
</code></pre>
</div>

<p>Now we can install <code class="highlighter-rouge">pip</code> with <code class="highlighter-rouge">easy_install</code> using the following command:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>easy_install-2.7 pip
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek5.png" alt="saptek5" /></p>

<p><code class="highlighter-rouge">pip</code> makes it really easy to install the Python packages. We will use <code class="highlighter-rouge">pip</code> to install the data science packages we might need using the following command:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>pip install numpy scipy pandas

pip install scikit-learn tornado pyzmq

pip install pygments matplotlib jsonschema

pip install jinja2 --upgrade
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek6.png" alt="saptek6" /></p>

<p>Finally, we are ready to install IPython notebook using <code class="highlighter-rouge">pip</code> using the following command:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>pip install <span class="s2">"ipython[notebook]"</span>
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek8.png" alt="saptek8" /></p>

<h3 id="configuring-ipython">Configuring IPython</h3>

<p>Since we want to use IPython with Apache Spark we have to use the Python interpreter which is built with Apache Spark, <code class="highlighter-rouge">pyspark</code>, instead of the default Python interpreter.</p>

<p>As a first step of configuring that, let’s create a IPython profile for <code class="highlighter-rouge">pyspark</code></p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>ipython profile create pyspark
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek9.png" alt="saptek9" /></p>

<p>Next generate a jupyter config file:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>jupyter notebook --generate-config                                            
</code></pre>
</div>

<p>You should see the following output:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>Writing default config to: /root/.jupyter/jupyter_notebook_config.py
</code></pre>
</div>

<p>Now open your preferred editor. I’m using <code class="highlighter-rouge">nano</code> to edit <code class="highlighter-rouge">jupyter_notebook_config.py</code></p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>nano  ~/.jupyter/jupyter_notebook_config.py  
</code></pre>
</div>

<p>Next copy and paste the following:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">source</span> /opt/rh/python27/enable
<span class="nv">IPYTHON_OPTS</span><span class="o">=</span><span class="s2">"notebook --port 8889 </span><span class="se">\</span><span class="s2">
--notebook-dir='/usr/hdp/current/spark-client/' </span><span class="se">\</span><span class="s2">
--ip='*' --no-browser"</span> pyspark
</code></pre>
</div>

<p>Save and exit your editor.</p>

<p>For more info checkout: http://simnotes.github.io/blog/installing-jupyter-on-hdp-2.3.2/</p>

<p><img src="/assets/ipython-with-spark/saptek10.png" alt="saptek10" /></p>

<p>Next we are going to create a shell script to set the appropriate values every time we want to start IPython.</p>

<p>Create a shell script with the following command:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>nano ~/start_ipython_notebook.sh
</code></pre>
</div>

<p>Then copy the following lines into the file:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">source</span> /opt/rh/python27/enable

<span class="nv">IPYTHON_OPTS</span><span class="o">=</span><span class="s2">"notebook"</span> pyspark
</code></pre>
</div>

<p>Save and exit your editor.</p>

<p>Finally we need to make the shell script we just created executable:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>chmod +x start_ipython_notebook.sh
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/python.png" alt="python" /></p>

<h3 id="port-forwarding">Port Forwarding</h3>

<p>We need to forward the port <code class="highlighter-rouge">8889</code> from the guest VM, Sandbox to the host machine, your desktop for IPython notebook to be accessible from a browser on your host machine.</p>

<p>Open the VirtualBox App and open the settings page of the Sandbox VM by right clicking on the Sandbox VM and selecting settings.</p>

<p>Then select the networking tab from the top:</p>

<p><img src="/assets/ipython-with-spark/saptek13.png" alt="saptek13" /></p>

<p>Then click on the port forwarding button to configure the port. Add a new port configuration by clicking the <code class="highlighter-rouge">+</code> icon on the top right of the page.</p>

<p>Input a name for application, IP and the guest and host ports as per the screenshot below:</p>

<p><img src="/assets/ipython-with-spark/saptek14.png" alt="saptek14" /></p>

<p>Then press <code class="highlighter-rouge">OK</code> to confirm the change in configuration.</p>

<p>Now we are ready to test IPython notebook.</p>

<h3 id="running-ipython-notebook">Running IPython notebook</h3>

<p>Execute the shell script we created before from the sandbox command prompt using the command below:</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>./start_ipython_notebook.sh
</code></pre>
</div>

<p><img src="/assets/ipython-with-spark/saptek15.png" alt="saptek15" /></p>

<p>Now, open a browser on your host machine and navigate to the URl <a href="http://127.0.0.1:8889">http://127.0.0.1:8889</a> and you should see the screen below:</p>

<p><img src="https://www.dropbox.com/s/2ga17v2a8klpdz9/Screenshot%202015-07-20%2011.22.06.png?dl=1" alt="" /></p>

<p>Voila! You have just configured IPython notebook with Apache Spark on you Sandbox.</p>

<p>In the next few tutorials we are going to explore how we can use IPython notebook to analyze and visualize data.</p>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-380.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-380&topics=hdp-2.4.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Using IPython Notebook with Apache Spark</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-380</strong> and <strong>hdp-2.4.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
