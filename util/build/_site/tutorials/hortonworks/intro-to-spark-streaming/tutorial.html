

<div class="tutorial-content">
  <p>In this tutorial, we will introduce core concepts of Apache Spark Streaming and run a Word Count demo that computes an incoming list of words every two seconds.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>This tutorial is a part of series of hands-on tutorials to get you started with HDP using Hortonworks Sandbox. Please ensure you complete the prerequisites before proceeding with this tutorial.</p>

<ul>
  <li>Downloaded and Installed latest <a href="http://hortonworks.com/products/hortonworks-sandbox/#install">Hortonworks Sandbox</a></li>
</ul>

<p><strong>Note</strong>: if you are attending a Meetup/Crash Course your speaker/instructor may have additional instructions regarding the Sandbox VM image.</p>

<ul>
  <li><a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a></li>
</ul>

<h3 id="concepts">Concepts</h3>

<p>Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. Data can be ingested from many sources like Kafka, Flume, Twitter, ZeroMQ, Kinesis, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window. Finally, processed data can be pushed out to filesystems, databases, and live dashboards.</p>

<p><img src="http://spark.apache.org/docs/1.6.0/img/streaming-arch.png" alt="Spark Streaming" /></p>

<p>Internally, it works as follows. Spark Streaming receives live input data streams and divides the data into batches, which are then processed by the Spark engine to generate the final stream of results in batches.</p>

<p><img src="http://spark.apache.org/docs/1.6.0/img/streaming-flow.png" alt="Spark Streaming" /></p>

<p><strong>DStream</strong></p>

<p>Discretized Stream or DStream is the basic abstraction provided by Spark Streaming. It represents a continuous stream of data, either the input data stream received from source, or the processed data stream generated by transforming the input stream. Internally, a DStream is represented by a continuous series of RDDs, which is Spark's abstraction of an immutable, distributed dataset (see <a href="http://spark.apache.org/docs/1.6.0/programming-guide.html#resilient-distributed-datasets-rdds">Spark Programming Guide</a> for more details).</p>

<h3 id="setup">Setup</h3>

<p><strong>1. Start your Sandbox</strong></p>

<p>First, start your Sandbox Virtual Machine (VM) in either a VirtualBox or VMware environment and note your VM IP address.</p>

<p>We will refer to your VM IP address as <code class="highlighter-rouge">&lt;HOST IP&gt;</code> throughout this tutorial.</p>

<p>If you need help finding your <code class="highlighter-rouge">&lt;HOST IP&gt;</code> checkout <a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/#learn-host-address-environment">Learning the Ropes</a>.</p>

<p><strong>2. Launch a "Shell in a Box"</strong></p>

<p>Now that your Sandbox is running, open a web browser and go to: <code class="highlighter-rouge">http://&lt;HOST IP&gt;:4200</code></p>

<p>Where <code class="highlighter-rouge">&lt;HOST IP&gt;</code> is the IP address of your Sandbox machine.</p>

<p>For example, the default address for <strong>VirtualBox</strong> is <a href="http://127.0.0.1:4200">http://127.0.0.1:4200</a></p>

<p>Next, log into the "Shell in a Box" using the following <em>default</em> credentials: <br /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>User: root
Pass: hadoop
</code></pre>
</div>

<p>If you're logging for the first time you will be required to change your password.</p>

<p><strong>3. Download a Spark Streaming Demo to Sandbox</strong></p>

<p>Now let's download a Spark Streaming demo code to your sandbox from GitHub.</p>

<p>In your "Shell in a Box" execute the following two commands:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>cd /tmp
</code></pre>
</div>

<p>and</p>

<div class="highlighter-rouge"><pre class="highlight"><code>wget https://raw.githubusercontent.com/roberthryniewicz/sample-code/master/spark-streaming-demo.py
</code></pre>
</div>

<p><strong>Note</strong>: <code class="highlighter-rouge">wget &lt;url&gt;</code> downloads Spark Streaming code that computes a simple Word Count. Words (i.e. strings) will be coming in via a network socket connection from a simple Netcat tool introduced later.</p>

<p>Several things worth pointing out in the demo code you've just downloaded:</p>
<ol>
  <li>We've set a 2 sec batch interval to make it easier to inspect results of each batch processed.</li>
  <li>We perform a simple word count for each batch and return the results back to the terminal screen with a <code class="highlighter-rouge">pprint()</code> function.</li>
</ol>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">pyspark.streaming</span> <span class="kn">import</span> <span class="n">StreamingContext</span>

<span class="c"># Create a local StreamingContext with two working threads and a batch interval of 2 seconds</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s">"local[2]"</span><span class="p">,</span> <span class="s">"NetworkWordCount"</span><span class="p">)</span>
<span class="n">ssc</span> <span class="o">=</span> <span class="n">StreamingContext</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c"># Create a DStream</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">socketTextStream</span><span class="p">(</span><span class="s">"localhost"</span><span class="p">,</span> <span class="mi">3333</span><span class="p">)</span>

<span class="c"># Split each line into words</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span>

<span class="c"># Count each word in each batch</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">wordCounts</span> <span class="o">=</span> <span class="n">pairs</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span>

<span class="c"># Print each batch</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="n">pprint</span><span class="p">()</span>

<span class="n">ssc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>             <span class="c"># Start the computation</span>
<span class="n">ssc</span><span class="o">.</span><span class="n">awaitTermination</span><span class="p">()</span>  <span class="c"># Wait for the computation to terminate</span>
</code></pre>
</div>

<p><strong>4. Submit a Spark Streaming Job</strong></p>

<p>Now you're ready to submit a Spark job. In your terminal window copy and paste the following and hit <code class="highlighter-rouge">Enter</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/usr/hdp/current/spark-client/bin/spark-submit /tmp/spark-streaming-demo.py
</code></pre>
</div>

<p>You should see lots of INFO interspersed with Timestamp corresponding to each batch that is updated every 2 seconds:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>===========================================
Time: 2016-03-16 01:26:22
===========================================
</code></pre>
</div>

<p><strong>5. Run Netcat</strong></p>

<p>Netcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP.</p>

<p>In your browser, open a second tab or window, and open another "Shell in a Box" by going to <code class="highlighter-rouge">http://&lt;Host IP&gt;:4200</code>.</p>

<p>For example, <a href="http://127.0.0.1:4200">http://127.0.0.1:4200</a> if you're running a <strong>VirtualBox</strong>.</p>

<p>Login to your <em>shell</em> and run the following command to launch Netcat:</p>

<div class="highlighter-rouge"><pre class="highlight"><code> nc -l localhost 3333
</code></pre>
</div>

<p>At this point you should be connected and you may start typing or pasting any text.</p>

<p>For example, if you type the following <code class="highlighter-rouge">hello hello world</code> text in the Netcat window, you should see the following output in the already running Spark Streaming job tab or window:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>===========================================
Time: 2016-03-16 01:26:24
===========================================
(hello, 2)
(world, 1)
</code></pre>
</div>

<p><strong>6. Stopping Spark Streaming and Netcat</strong></p>

<p>When you're done experimenting, press <code class="highlighter-rouge">Ctrl + C</code> in your  shell tab or window to stop your Spark Job and/or Netcat process.</p>

<p><strong>7. Suppressing INFO Messages (Optional)</strong></p>

<p>If you want to remove annoying INFO messages from the Spark streaming terminal window, do the following:</p>

<p>Open <code class="highlighter-rouge">conf/log4j.properties</code>, for example:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>vi /usr/hdp/current/spark-client/conf/log4j.properties
</code></pre>
</div>

<p>and Edit log4j.properties:</p>

<div class="highlighter-rouge"><pre class="highlight"><code># Set everything to be logged to the console
log4j.rootCategory=INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
</code></pre>
</div>

<p>Replace the first line:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>log4j.rootCategory=INFO, console
</code></pre>
</div>

<p>with</p>

<div class="highlighter-rouge"><pre class="highlight"><code>log4j.rootCategory=WARN, console
</code></pre>
</div>

<p>Save log4j.properties and restart your spark-submit job. Now you should see only <strong>WARN</strong> messages.</p>

<h3 id="further-resources">Further Resources</h3>

<p>Once you've completed this tutorial, checkout other <a href="http://hortonworks.com/hadoop/spark/#tutorials">Spark Tutorials</a>.</p>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-366.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-366&topics=hdp-2.5.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Intro to Spark Streaming</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-366</strong> and <strong>hdp-2.5.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
