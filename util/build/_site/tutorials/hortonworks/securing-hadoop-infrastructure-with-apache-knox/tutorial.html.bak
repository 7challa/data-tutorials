

<div class="tutorial-content">
  <h2 id="introduction">Introduction</h2>

<p>In this tutorial we will walk through the process of</p>

<ul>
  <li>Configuring Apache Knox and LDAP services on HDP Sandbox</li>
  <li>Run a MapReduce Program using Apache Knox Gateway Server</li>
</ul>

<h2 id="what-is-apache-knox">What is Apache Knox?</h2>

<p>The <a href="http://hortonworks.com/hadoop/knox">Apache Knox Gateway</a> is a system that provides a single point of authentication and access for Apache™ Hadoop® services. It provides the following features:</p>

<ul>
  <li>Single REST API Access Point</li>
  <li>Centralized authentication, authorization and auditing for Hadoop REST/HTTP services</li>
  <li>LDAP/AD Authentication, Service Authorization and Audit</li>
  <li>Eliminates SSH edge node risks</li>
  <li>Hides Network Topology</li>
</ul>

<h2 id="layers-of-defense-for-a-hadoop-cluster">Layers of Defense for a Hadoop Cluster</h2>

<ul>
  <li>Perimeter Level Security – Network Security, Apache Knox (gateway)</li>
  <li>Authentication : Kerberos</li>
  <li>Authorization</li>
  <li>OS Security : encryption of data in network and HDFS</li>
</ul>

<p>Apache Knox can also access a Hadoop cluster over HTTP or HTTPS</p>

<h2 id="current-features-of-apache-knox">Current Features of Apache Knox</h2>

<ul>
  <li>Authenticate : by LDAP or Cloud SSO Provider</li>
  <li>Provides services for HDFS, HCat, HBase, Oozie, Hive, YARN, and Storm</li>
  <li>HTTP access for Hive over JDBC support is available (ODBC driver Support- In Future)</li>
</ul>

<h2 id="prerequisites">Prerequisites:</h2>

<ul>
  <li><a href="http://hortonworks.com/downloads/#sandbox">Download Hortonworks 2.5 Sandbox</a>.</li>
  <li>Complete the <a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox tutorial,</a> you will need it for logging into Ambari.</li>
</ul>

<h2 id="outline">Outline</h2>

<ul>
  <li><a href="#start-knox">1: Start Knox and DEMO LDAP service</a></li>
  <li><a href="#check-webhdfs">2: Check the accessibility of WebHDFS</a></li>
  <li><a href="#access-cluster-knox">3: Accessing Hadoop Cluster via Knox</a></li>
  <li><a href="#run-job-knox">4: Run the WordCount Job via Knox</a></li>
  <li><a href="#check-status-job">5: Check the Status of the Job</a></li>
  <li><a href="#view-directories">6: View the List of HDFS Directories</a></li>
  <li><a href="#list-output-result">7: List the Output Result</a></li>
  <li><a href="#view-output-file">8: View the Output File</a></li>
  <li><a href="#further-reading">Links and Further Reading</a></li>
</ul>

<h3 id="1-start-knox-and-demo-ldap-service-">1: Start Knox and DEMO LDAP service <a id="start-knox"></a></h3>

<p>Open up the Ambari user interface by using the URL http://sandbox.hortonworks.com:8080.<br />
Using Virtualbox it might look like http://127.0.0.1:8080. If you’re using Azure make sure to replace 127.0.0.1 with you host machine’s IP address.</p>

<p>Login to Ambari using the following:<br />
Username - <strong>raj_ops</strong><br />
Password - <strong>raj_ops</strong></p>

<p>After logging in to Ambari, you will see a list of Services.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/ambari_dashboard_rajops.png" alt="ambari_dashboard_rajops" /></p>

<p>Now Select <code class="highlighter-rouge">Knox</code> from the list of Services on the left-hand side of the page.<br />
Then click on <code class="highlighter-rouge">Service Actions</code> from the top right hand side of the page click on <code class="highlighter-rouge">Start</code>.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/start_knox.png" alt="start_knox" /></p>

<p>Check the box for <code class="highlighter-rouge">Maintenance Mode</code> and click <code class="highlighter-rouge">Confirm Start</code>.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/knox_maintenance_mode.png" alt="knox_maintenance_mode" /></p>

<p>Next, then go back to the <code class="highlighter-rouge">Service Actions</code> button on the Knox service and click on <code class="highlighter-rouge">Start DemoLDAP</code>. This LDAP server is when authenticating users against Knox in the Sandbox because there is no other LDAP server running on the Sandbox.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/start_demo_ldap.png" alt="start_demo_ldap" /></p>

<p>Now that Knox has started we can start trying to route requests through it. For this next section you’re going to need access to a terminal which utilizes the curl command.</p>

<p>Next, log in to your Sandbox via SSH.<br />
If you’re using Virtualbox you can log in with the command:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ssh root@127.0.0.1 -p 2222
</code></pre>
</div>

<p>The first time password to log in is: <strong>hadoop</strong></p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/sshTerminal.png" alt="sshTerminal" /></p>

<h3 id="2-check-the-accessibility-of-webhdfs-">2: Check the accessibility of WebHDFS <a id="check-webhdfs"></a></h3>

<p>Let’s check if the Hadoop Cluster is accessible via <strong>WebHDFS</strong>.
Note that this request is directly accessing the WebHDFS API. This means that we are sending our request directly to WebHDFS without any security or encryption.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>touch /usr/hdp/current/knox-server/conf/topologies/knox_sample.xml
curl -iku guest:guest-password -X GET 'http://sandbox.hortonworks.com:50070/webhdfs/v1/?op=LISTSTATUS'
</code></pre>
</div>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/touch_knox_sample.png" alt="touch_knox_sample" /></p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/access_webhdfs.png" alt="access_webhdfs" /></p>

<h3 id="3-accessing-hadoop-cluster-via-knox-">3: Accessing Hadoop Cluster via Knox <a id="access-cluster-knox"></a></h3>

<p>Now let’s check if we can access Hadoop Cluster via Apache Knox services. Using Knox means we can utilize the HTTPS protocol which utilizes SSL to encrypt our requests and makes using it much more secure.</p>

<p>Not only do we get the added benefit of the extra layer of protection with encryption, but we also get to plug in the LDAP server which many organizations already utilize for authentication</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password -X GET 'https://sandbox.hortonworks.com:8443/gateway/default/webhdfs/v1/?op=LISTSTATUS'
</code></pre>
</div>

<p>This requests routes through the Knox Gateway. Note that here we use the HTTPS protocol meaning our request is completely encrypted. This is great if, for example, you wanted to access Hadoop services via an insecure medium such as the internet.</p>

<h3 id="4-run-the-wordcount-job-via-knox-">4: Run the WordCount Job via Knox <a id="run-job-knox"></a></h3>

<p>Let’s work on an End to end implementation use case using Apache Knox Service. Here we will take a simple example of a mapreduce jar that you might be already familiar with, the WordCount mapreduce program. We will first create the needed directories, upload the datafile into hdfs and also upload the mapreduce jar file into hdfs. Once these steps are done, using Apache Knox service, we will run this jar and process data to produce output result.</p>

<p><strong>NOTE:</strong> If you get error “{“error”:”User: hcat is not allowed to impersonate guest”}”, do</p>

<div class="highlighter-rouge"><pre class="highlight"><code>usermod -a -G users guest
</code></pre>
</div>

<p>Let’s go!</p>

<div class="highlighter-rouge"><pre class="highlight"><code>cd /usr/hdp/current/knox-server
</code></pre>
</div>

<p>You could create the directories <code class="highlighter-rouge">knox-sample</code>, <code class="highlighter-rouge">knox-sample/input</code>, and <code class="highlighter-rouge">knox-sample/lib</code> as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password -X put 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample?op=MKDIRS&amp;permission=777'

curl -iku guest:guest-password -X put 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/input?op=MKDIRS&amp;permission=777'

curl -iku guest:guest-password -X put 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/lib?op=MKDIRS&amp;permission=777'

curl -iku guest:guest-password -X put 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/output?op=MKDIRS&amp;permission=777'

</code></pre>
</div>

<p>Note that if you don’t get the <code class="highlighter-rouge">HTTP/1.1 200 OK</code> Return as a result, you may not have started the Knox LDAP server</p>

<p>Let’s upload the data and the mapreduce jar files:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password  -L -T README -X PUT  "https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/input/README?op=CREATE"

curl -iku guest:guest-password  -L -T /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar -X PUT "https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/lib/hadoop-mapreduce-examples.jar?op=CREATE"
</code></pre>
</div>

<p>Let’s run the mapreduce program.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password --connect-timeout 60 -X POST -d 'arg=/user/guest/knox-sample/input' -d 'arg=/user/guest/knox-sample/output/wordcount' -d 'jar=/user/guest/knox-sample/lib/hadoop-mapreduce-examples.jar' -d class=wordcount https://sandbox.hortonworks.com:8443/gateway/knox_sample/templeton/v1/mapreduce/jar
</code></pre>
</div>

<p>When you run the mapreduce execution step, you will see the following result. Please note down the Job Id. You will use it for checking status for this Job Id in the next step.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/run_job.png" alt="run_job" /></p>

<h3 id="5-check-the-status-of-the-job-">5: Check the Status of the Job <a id="check-status-job"></a></h3>

<p>You can check the status of your above Job Id as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/templeton/v1/jobs/job_1476726325748_0007'
</code></pre>
</div>

<p>Remember to <strong>replace everything after <code class="highlighter-rouge">jobs/</code> with your job id</strong>.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/check_status.png" alt="check_status" /></p>

<h3 id="6-view-the-list-of-hdfs-directories-">6: View the List of HDFS Directories <a id="view-directories"></a></h3>

<p>Let’s look at the list of directories in /knox-sample parent directory in hdfs.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password -X GET 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample?op=LISTSTATUS'
</code></pre>
</div>

<p>These are the directories which we created earlier.</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/list_directories.png" alt="list_directories" /></p>

<h3 id="7-list-the-output-result-">7: List the Output Result <a id="list-output-result"></a></h3>

<p>Let’s look at the output result file.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password -X GET 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/output/wordcount?op=LISTSTATUS'
</code></pre>
</div>

<p>It should look something like below:</p>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/list_output_file.png" alt="list_output_file" /></p>

<h3 id="8-view-the-output-file-">8: View the Output File <a id="view-output-file"></a></h3>

<p>Let’s look at the output result.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl -iku guest:guest-password -L -X GET 'https://sandbox.hortonworks.com:8443/gateway/knox_sample/webhdfs/v1/user/guest/knox-sample/output/wordcount/part-r-00000?op=OPEN'
</code></pre>
</div>

<p><img src="/assets/securing-hadoop-infrastructure-with-apache-knox/view_output_file.png" alt="view_output_file" /></p>

<p>You just ran a mapreduce program on Hadoop through the Apache Knox Gateway!</p>

<p>Remember, <strong>Knox</strong> is a great way to remotely access API’s form your Hadoop cluster securely. You can add many different core Hadoop services to it, and you can even create your own services which you can route through the Gateway. This can keep your cluster safe and secure. Not to mention that there is great LDAP integration for organizations as well.</p>

<h2 id="links-and-further-reading-">Links and Further Reading <a id="further-reading"></a></h2>

<ul>
  <li><a href="https://community.hortonworks.com/search.html?f=&amp;type=question&amp;redirect=search%2Fsearch&amp;sort=relevance&amp;q=knox">Knox on Hortonworks Community Connection</a></li>
  <li><a href="http://knox.apache.org">Apache Knox Site</a></li>
  <li><a href="http://kminder.github.io/knox/2015/11/18/setting-up-knox.html">How to set up Apache Knox</a></li>
  <li><a href="http://kminder.github.io/knox/2015/11/16/adding-a-service-to-knox.html">Adding a Service to Knox</a></li>
  <li><a href="http://kminder.github.io/knox/2015/11/18/knox-with-activedirectory.html">Using Knox with Microsoft Active Directory</a></li>
</ul>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-420.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-420&topics=hdp-2.5.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Securing Your Hadoop Infrastructure with Apache Knox</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-420</strong> and <strong>hdp-2.5.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
