

<div class="tutorial-content">
  <h3 id="introduction">Introduction</h3>

<p>In this tutorial we will explore how you can use policies in Apache Ranger to protect your enterprise data lake and audit access by users to resources on HDFS, Hive and HBase from a centralized Ranger Administration Console.</p>

<h3 id="prerequisites">Prerequisites</h3>

<ul>
  <li>Download <a href="http://hortonworks.com/products/hortonworks-sandbox/#install">Hortonworks Sandbox</a></li>
  <li>Complete the <a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the HDP Sandbox</a> tutorial.</li>
</ul>

<h3 id="login-to-the-ranger-administration-console">Login to the Ranger Administration Console</h3>

<p>Once the VM is running in VirtualBox, login to the Ranger Administration console at <a href="http://localhost:6080/">http://localhost:6080/</a> from your host machine. The username is <code class="highlighter-rouge">admin</code> and the password is <code class="highlighter-rouge">admin</code>.</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/ranger-login.png" alt="" /></p>

<p>As soon as you login, you should see list of repositories as shown below:</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/main-policies.png" alt="" /></p>

<h3 id="review-existing-hdfs-policies">Review existing HDFS policies</h3>

<p>Please click on <code class="highlighter-rouge">Sandbox_hadoop</code> link under HDFS section</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/hdfs-policies.png" alt="" /></p>

<p>User can review policy details by a single click on the policy. The policy details will appear on the right.</p>

<p>Click on the <strong>HDFS Global Allow</strong> policy. Click the slider so it is in <strong>disable</strong> position. Then click <strong>Save</strong>.</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/disable-hdfs-policy.png" alt="" /></p>

<h3 id="exercise-hdfs-access-scenarios">Exercise HDFS access scenarios</h3>

<p>To validate the policy, please login into the sandbox using username <code class="highlighter-rouge">it1</code>. User <code class="highlighter-rouge">it1</code> belongs to the <code class="highlighter-rouge">IT</code> group.</p>

<p>Login to the Sandbox VM.</p>

<p>You can SSH:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ssh -p 2222 root@127.0.0.1
</code></pre>
</div>

<p>Or you could choose to use the VirtualBox Shell</p>

<p>use the password <code class="highlighter-rouge">hadoop</code>.</p>

<p>Try running the following commands:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>su it1
id
hdfs dfs -cat /demo/data/Customer/acct.txt
</code></pre>
</div>

<p>You should get a result similar to the following</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[root@sandbox ~]# su - it1
[it1@sandbox ~]$ id uid=1018(it1)  gid=1018(IT)  groups=1018(IT)
[it1@sandbox ~]$ hdfs dfs -cat /demo/data/Customer/acct.txt
cat:  Permission denied:  user=it1,  access=READ,  inode="/demo/data/Customer/acct.txt":hdfs:hdfs:-rwx------
</code></pre>
</div>

<p>Go to the Auditing Tab and check that its access (denied) being audited. You can filter</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/audit-deny-1.png" alt="" /></p>

<p>Now, go back to the HDFS Global Allow Policy. Click the switch to enable it and try running the command again</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/enable-hdfs-global-allow.png" alt="" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>hdfs dfs -cat /demo/data/Customer/acct.txt
</code></pre>
</div>

<p>You should be greeted with many rows of data after running the command with the policy enabled.</p>

<p>Now head back to the audit tab in Ranger and search by user: <code class="highlighter-rouge">it1</code>. Here you can see that the request was Allowed through</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/audit-it1.png" alt="" /></p>

<h3 id="review-hive-policies">Review Hive Policies</h3>

<p>Click on PolicyManager section on the top menu, then click on <code class="highlighter-rouge">Sandbox_hive</code> link under HIVE section to view list of Hive Policies</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/hive-policies.png" alt="" /></p>

<p>User can review policy details by a single click on the policy. The policy details will appear on the right.</p>

<p><em>Disable</em> the <strong>Hive Global Tables Allow Policy</strong> like</p>

<h3 id="exercise-hive-access-scenarios">Exercise Hive Access Scenarios</h3>

<p>Run the <code class="highlighter-rouge">beeline</code> command to validate access for <code class="highlighter-rouge">mktg1</code> user to see if he can run <code class="highlighter-rouge">select  *  from  xademo.customer_details</code></p>

<p>You can copy and paste the following commands to start beeline:</p>

<p>Make sure you first run <code class="highlighter-rouge">exit</code> to log out of the <code class="highlighter-rouge">it1</code> user, then run the following:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>su mktg1
beeline -u "jdbc:hive2://localhost:10000/default" -n mktg1 -p mktg1 -d org.apache.hive.jdbc.HiveDriver
</code></pre>
</div>

<p>Then once beeline is started run:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>select * from xademo.customer_details
</code></pre>
</div>

<p>You should get an error like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>0: jdbc:hive2://localhost:10000/default&gt; select * from xademo.customer_details;
Error: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [mktg1] does not have [SELECT] privilege on [xademo/customer_details/balance,imei,phone_number,plan,rec_date,region,status] (state=42000,code=40000)
</code></pre>
</div>

<p>Go to Policy Administrator tool and see its access (denied) being audited. You can do this the same way that we checked for the <code class="highlighter-rouge">it1</code> user. Just search the audit log by user to see.</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/hive-audit-1.png" alt="" /></p>

<p>Re-Enable the <strong>Global Hive Tables Allow</strong> policy. Then try running the same beeline command again.</p>

<p>Go to Policy Administrator tool and see its access (granted) being audited.</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/hive-audit-2.png" alt="" /></p>

<h3 id="review-hbase-policies">Review HBase Policies</h3>

<p>Click on PolicyManager section on the top menu, then click on the <code class="highlighter-rouge">Sandbox_hbase</code> link under <strong>HBASE</strong> section to view list of hbase Policies.</p>

<p><img src="https://raw.githubusercontent.com/hortonworks/tutorials/hdp/assets/securing-data-lake-with-ranger/hbase-policies.png" alt="" /></p>

<p>User can review policy details by a single click on the policy. The policy details will appear on the right.</p>

<p>Disable the <strong>HBase Global Allow</strong> Policy in the same manner that we did before.</p>

<h3 id="exercise-hbase-access-scenarios">Exercise HBase access scenarios</h3>

<p>Log out of user <code class="highlighter-rouge">mktg1</code> by typing <code class="highlighter-rouge">exit</code> into the terminal. Make sure that the prompt shows
<code class="highlighter-rouge">[root@sandbox ~]#</code>.</p>

<p>Run the following command to start HBase</p>

<div class="highlighter-rouge"><pre class="highlight"><code>./start_hbase.sh
</code></pre>
</div>

<p>You will get something like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[root@sandbox ~]# ./start_hbase.sh
Starting HBase...
Starting Postgre SQL                                      [  OK  ]
Starting name node                                        [  OK  ]
Starting zookeeper nodes                                  [  OK  ]
Starting hbase master                                     [  OK  ]
Starting hbase stargate                                   [  OK  ]
Starting hbase thrift                                     [  OK  ]
Starting hbase regionservers                              [  OK  ]
====================================

HBase autostart enabled
To disable auto-start of HBase do
  # chkconfig hbase-starter off

====================================
</code></pre>
</div>

<p>Run the hbase shell command to validate access for <code class="highlighter-rouge">it1</code> user-id, who belongs to <code class="highlighter-rouge">IT</code> group to see if he can view table data from the <code class="highlighter-rouge">iemployee</code> table:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>su it1
hbase shell
</code></pre>
</div>

<p>Once at the HBase Shell, run:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>get 'iemployee', '1'
</code></pre>
</div>

<p>You should get a message similar to:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>COLUMN                      CELL

ERROR: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user 'it1',action: get, tableName:iemployee, family:payroll.

Here is some help for this command:
Get row or cell contents; pass table name, row, and optionally
a dictionary of column(s), timestamp, timerange and versions. Examples:

  hbase&gt; get 'ns1:t1', 'r1'
  hbase&gt; get 't1', 'r1'
  hbase&gt; get 't1', 'r1', {TIMERANGE =&gt; [ts1, ts2]}
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1'}
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; ['c1', 'c2', 'c3']}
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1}
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', TIMERANGE =&gt; [ts1, ts2], VERSIONS =&gt; 4}
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1, VERSIONS =&gt; 4}
  hbase&gt; get 't1', 'r1', {FILTER =&gt; "ValueFilter(=, 'binary:abc')"}
  hbase&gt; get 't1', 'r1', 'c1'
  hbase&gt; get 't1', 'r1', 'c1', 'c2'
  hbase&gt; get 't1', 'r1', ['c1', 'c2']
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', ATTRIBUTES =&gt; {'mykey'=&gt;'myvalue'}}
  hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', AUTHORIZATIONS =&gt; ['PRIVATE','SECRET']}
  hbase&gt; get 't1', 'r1', {CONSISTENCY =&gt; 'TIMELINE'}
  hbase&gt; get 't1', 'r1', {CONSISTENCY =&gt; 'TIMELINE', REGION_REPLICA_ID =&gt; 1}

Besides the default 'toStringBinary' format, 'get' also supports custom formatting by
column.  A user can define a FORMATTER by adding it to the column name in the get
specification.  The FORMATTER can be stipulated:

 1. either as a org.apache.hadoop.hbase.util.Bytes method name (e.g, toInt, toString)
 2. or as a custom class followed by method name: e.g. 'c(MyFormatterClass).format'.

Example formatting cf:qualifier1 and cf:qualifier2 both as Integers:
  hbase&gt; get 't1', 'r1' {COLUMN =&gt; ['cf:qualifier1:toInt',
    'cf:qualifier2:c(org.apache.hadoop.hbase.util.Bytes).toInt'] }

Note that you can specify a FORMATTER by column only (cf:qualifier).  You cannot specify
a FORMATTER for all columns of a column family.

The same commands also can be run on a reference to a table (obtained via get_table or
create_table). Suppose you had a reference t to table 't1', the corresponding commands
would be:

  hbase&gt; t.get 'r1'
  hbase&gt; t.get 'r1', {TIMERANGE =&gt; [ts1, ts2]}
  hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1'}
  hbase&gt; t.get 'r1', {COLUMN =&gt; ['c1', 'c2', 'c3']}
  hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1}
  hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1', TIMERANGE =&gt; [ts1, ts2], VERSIONS =&gt; 4}
  hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1, VERSIONS =&gt; 4}
  hbase&gt; t.get 'r1', {FILTER =&gt; "ValueFilter(=, 'binary:abc')"}
  hbase&gt; t.get 'r1', 'c1'
  hbase&gt; t.get 'r1', 'c1', 'c2'
  hbase&gt; t.get 'r1', ['c1', 'c2']
  hbase&gt; t.get 'r1', {CONSISTENCY =&gt; 'TIMELINE'}
  hbase&gt; t.get 'r1', {CONSISTENCY =&gt; 'TIMELINE', REGION_REPLICA_ID =&gt; 1}
</code></pre>
</div>

<p>Now go ahead and re-enable the <strong>HBASE Global Allow</strong> policy. Run the same command at the hbase shell</p>

<div class="highlighter-rouge"><pre class="highlight"><code>get 'iemployee', '1'
</code></pre>
</div>

<p>Then you should get an output like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hbase(main):016:0&gt; get 'iemployee', '1'
COLUMN                      CELL
 insurance:dental           timestamp=1456405966724, value=metlife
 insurance:health           timestamp=1456405966696, value=anthem
 insurance:life             timestamp=1456405966778, value=metlife
 insurance:vision           timestamp=1456405966751, value=visionOne
 payroll:grade              timestamp=1456405966585, value=G16
 payroll:salary             timestamp=1456405966613, value=250000.00
 personal:city              timestamp=1456405966479, value=San Fransisco
 personal:fname             timestamp=1456405966352, value=Mike
 personal:lname             timestamp=1456405966436, value=Young
 personal:zip               timestamp=1456405966553, value=12345
 skills:interpersonal-ratin timestamp=1456405966669, value=medium
 g
 skills:management          timestamp=1456405966642, value=executive,creator,innovative
12 row(s) in 0.0280 seconds
</code></pre>
</div>

<p>Don't forget to check the audit logs for this too!</p>

<h3 id="summary">Summary</h3>

<p>Hopefully by following this tutorial, you got a taste of the power and ease of securing your key enterprise resources using Apache Ranger.</p>

<p>Happy Hadooping!!!</p>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-570.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-570&topics=hdp-2.4.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Securing Data Lake Resources and Auditing User Access with Apache Ranger Security</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-570</strong> and <strong>hdp-2.4.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
