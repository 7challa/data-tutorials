

<div class="tutorial-content">
  <h1 id="lab-2-ingest-and-process-real-time-events-with-apache-storm">Lab 2: Ingest and Process Real-time Events with Apache Storm</h1>

<h3 id="introduction">Introduction</h3>

<p>The Trucking business is a high-risk business in which truck drivers venture into remote areas, often in  harsh weather conditions and chaotic traffic on a daily basis. Using this solution illustrating Modern Data Architecture with Hortonworks Data Platform, we have developed a centralized management system that can help reduce risk and lower the total cost of operations.</p>

<p>This system can take into consideration adverse weather conditions, the driver’s driving patterns, current traffic conditions and other criteria to alert and inform the management staff and the drivers themselves when risk factors run high.</p>

<p>In the <a href="http://hortonworks.com/hadoop-tutorial/simulating-transporting-realtime-events-stream-apache-kafka/">previous tutorial</a>, you  learned to collect this data using Apache Kafka.</p>

<p>In this tutorial, you  will use <a href="http://hortonworks.com/labs/storm/"><strong>Apache Storm</strong></a> on the Hortonworks Data Platform to capture these data events and process them in real time for further analysis.</p>

<p>In this tutorial, you will learn the following topics:</p>

<ul>
  <li>Manage Storm on HDP.</li>
  <li>Create a Storm spout to consume the Kafka <code class="highlighter-rouge">truckevents</code> generated in <a href="http://hortonworks.com/hadoop-tutorial/simulating-transporting-realtime-events-stream-apache-kafka/">Lab #1</a>.</li>
</ul>

<h2 id="pre-requisites">Pre-Requisites</h2>

<ul>
  <li><a href="http://hortonworks.com/hadoop-tutorial/simulating-transporting-realtime-events-stream-apache-kafka/">Tutorial #1 Simulate and Transport Real Time Event Stream with Kafka.</a></li>
  <li>Downloaded and Installed the latest <a href="http://hortonworks.com/products/hortonworks-sandbox/#install">Hortonworks Sandbox</a></li>
  <li><a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a></li>
</ul>

<h2 id="outline">Outline</h2>

<ul>
  <li><a href="#apache-storm-lab2">Apache Storm basics</a></li>
  <li><a href="#start-configure-storm-lab2">Step 1: Apache Storm Configurations</a></li>
  <li><a href="#create-storm-topology-lab2">Step 2: Create Storm Topology</a></li>
  <li><a href="#code-review-lab2">Step 3: Code Review</a></li>
  <li><a href="#appendix-a-compile-storm-topology-lab2">Appendix A: Compile Storm Topology</a></li>
  <li><a href="#appendix-b-setup-storm-topology-eclipse-project-lab2">Appendix B: Setup Storm Topology as Eclipse Project</a></li>
  <li><a href="#further-reading-lab2">Further Reading</a></li>
</ul>

<h2 id="apache-storm-a-idapache-storm-lab2a">Apache Storm <a id="apache-storm-lab2"></a></h2>

<p>Apache Storm is an Open Source distributed, reliable, fault tolerant system for real time processing of data at high velocity.</p>

<p>It’s used for:</p>

<ul>
  <li>Real time analytics</li>
  <li>Online machine learning</li>
  <li>Continuous statics computations</li>
  <li>Operational Analytics</li>
  <li>And, to enforce Extract, Transform, and Load (ETL) paradigms.</li>
</ul>

<p>Spout and Bolt are the two main components in Storm, which work together to process streams of data.</p>

<ul>
  <li>Spout: Works on the source of data streams. In the “Truck Events” use case, Spout will read data from Kafka “truckevent” topics.</li>
  <li>Bolt: Spout passes streams of data to Bolt which processes and persists passes it to either a data store or sends it downstream to another Bolt.</li>
</ul>

<p>For details on Storm, <a href="http://hortonworks.com/labs/storm/">click here</a>.</p>

<h3 id="step-1-start-and-configure-storm-a-idstart-configure-storm-lab2a">Step 1: Start and Configure Storm <a id="start-configure-storm-lab2"></a></h3>

<h4 id="view-the-storm-services-page">1.1  View the Storm Services page</h4>

<p>Start by logging into Ambari as admin user. Refer to <a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/#setup-ambari-admin-password">Learning the Ropes of the Sandbox</a> if you have not setup your Ambari admin password. From the Dashboard page of Ambari, click on Storm from the list of installed services. (If you do not see Storm listed under Services, please follow click on Action -&gt; Add Service and select Storm and deploy it.)</p>

<p><img src="/assets/realtime-event-processing/t2-update/storm_action_services_left_column_iot.png" alt="Screen Shot 2015-06-04 at 4.23.34 PM.png" /></p>

<h4 id="start-storm">1.2  Start Storm</h4>

<p>From the Storm page, click on Service Actions -&gt; Start</p>

<p><img src="/assets/realtime-event-processing/t2-update/start_storm_service_iot.png" alt="Screen Shot 2015-06-04 at 4.26.41 PM.png" /></p>

<p>Check the box and click on Confirm Start:</p>

<p><img src="/assets/realtime-event-processing/t2-update/image19.png" alt="Screen Shot 2015-06-04 at 4.30.57 PM.png" /></p>

<p>Wait for Storm to start.</p>

<p><img src="/assets/realtime-event-processing/t2-update/started_storm_service_iot.png" alt="Screen Shot 2015-06-04 at 4.35.57 PM.png" /></p>

<h4 id="configure-storm">1.3  Configure Storm</h4>

<p>You can check the <strong>configurations</strong> below by pasting them into the Filter text box under the Service Actions dropdown.</p>

<p>1.   Check <strong>zookeeper configuration</strong>: ensure <code class="highlighter-rouge">storm.zookeeper.servers</code> is set to <code class="highlighter-rouge">sandbox.hortonworks.com</code></p>

<p><img src="/assets/realtime-event-processing/t2-update/zookeeper_configuration_iot.png" alt="Screen Shot 2015-06-04 at 4.38.57 PM.png" /></p>

<p>2.   Check the local directory configuration: ensure <code class="highlighter-rouge">storm.local.dir</code> is set to <code class="highlighter-rouge">/hadoop/storm</code></p>

<p><img src="/assets/realtime-event-processing/t2-update/local_dir_config_iot.png" alt="Screen Shot 2015-06-04 at 4.39.45 PM.png" /></p>

<p>3.   Check the <strong>nimbus host configuration</strong>: ensure <code class="highlighter-rouge">nimbus host</code> is set to <code class="highlighter-rouge">sandbox.hortonworks.com</code></p>

<p><img src="/assets/realtime-event-processing/t2-update/nimbus_host_config_iot.png" alt="Screen Shot 2015-06-04 at 4.41.09 PM.png" /></p>

<p>4.   Check the <strong>slots allocated</strong>: ensure <code class="highlighter-rouge">supervisor.slots.ports</code> is set to <code class="highlighter-rouge">[6700, 6701]</code></p>

<p><img src="/assets/realtime-event-processing/t2-update/slots_allocated_iot.png" alt="Screen Shot 2015-06-04 at 4.41.58 PM.png" /></p>

<p>5.   Check the <strong>UI configuration port</strong>: Ensure <code class="highlighter-rouge">ui.port</code> is set to <code class="highlighter-rouge">8744</code></p>

<p><img src="/assets/realtime-event-processing/t2-update/ui_config_port_iot.png" alt="Screen Shot 2015-06-04 at 4.54.16 PM.png" /></p>

<p>6.  Check the <strong>Storm UI</strong> from the Quick Links</p>

<p><img src="/assets/realtime-event-processing/t2-update/image03.png" alt="Screen Shot 2015-06-04 at 4.56.25 PM.png" /></p>

<p>Now you can see the UI:</p>

<p><img src="/assets/realtime-event-processing/t2-update/storm_user_interface_iot.png" alt="Storm UI" /></p>

<h3 id="step-2-create-a-storm-topology-a-idcreate-storm-topology-lab2a">Step 2: Create a Storm Topology <a id="create-storm-topology-lab2"></a></h3>

<h4 id="create-a-storm-spout-to-consume-the-kafka-truck-events-generated-in-tutorial-1">2.1 Create a Storm Spout to consume the Kafka truck events generated in Tutorial #1.</h4>

<p>1. Load data if required:</p>

<p>From Lab #1 you already have the required <a href="http://www.nyc.gov/html/dot/downloads/misc/all_truck_routes_nyc.kml">New York City truck routes</a> KML. If required, you can download the latest copy of the file with the following command.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>root@sandbox ~]# wget http://www.nyc.gov/html/dot/downloads/misc/all_truck_routes_nyc.kml --directory-prefix<span class="o">=</span>/opt/TruckEvents/Tutorials-master/src/main/resources/  
</code></pre>
</div>

<p>Recall that the source code is under the directory path</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/TruckEvents/Tutorials-master/src
</code></pre>
</div>

<p>The pre-compiled jars are under the directory path</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/TruckEvents/Tutorials-master/target
</code></pre>
</div>

<p><strong>(Optional)</strong> If you would like to modify/run the code:</p>

<ul>
  <li>refer to <a href="#appendix-a-compile-storm-topology">Appendix A</a> at the end of the tutorial for the steps to run maven to compile the jars to the target subdir from terminal command line</li>
  <li>refer to <a href="#appendix-b-setup-storm-topology-eclipse-project">Appendix B</a> at the end of the tutorial  for the steps to enable VNC (i.e. ‘remote desktop’) access on your sandbox and open/compile the code using Eclipse</li>
</ul>

<p>2. Verify that Kafka process is running</p>

<p>Verify that Kafka is running using Ambari dashboard. If not, start the Kafka service as we did in tutorial #1.</p>

<p><img src="/assets/realtime-event-processing/t2-update/verify_kafka_service_running_iot.png" alt="Screen Shot 2015-06-04 at 5.10.27 PM.png" /></p>

<p>3. Modify pom.xml File to Prepare for Creating Storm Topology</p>

<p>Before we create a Storm Topology, we need to modify our pom.xml file with the latest <code class="highlighter-rouge">storm.version</code> and <code class="highlighter-rouge">storm.kafka.version</code> from our current Sandbox, so our Topology will function correctly.</p>

<p>Navigate to the following directory</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>root@sandbox ~]# <span class="nb">cd</span> /opt/TruckEvents/Tutorials-master/
</code></pre>
</div>

<p>Open pom.xml file with vi editor</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>root@sandbox Tutorials-master]# vi pom.xml
</code></pre>
</div>

<p>The storm and storm.kafka version can be found under the **<properties>** tag similar to the image below:</properties></p>

<p><img src="/assets/realtime-event-processing/t2-update/pom_xml_file_version_modify_iot.png" alt="Screen Shot 2015-06-04 at 5.10.27 PM.png" /></p>

<blockquote>
  <p><strong>Note:</strong> storm.version and storm.kafka.version both fall under storm.version. To find the version of storm, use the command <code class="highlighter-rouge">storm version</code>.</p>
</blockquote>

<p>Now that we have modified our pom.xml file, let’s install maven and run a <code class="highlighter-rouge">mvn clean package</code> refer to Appendix A for details.</p>

<p>Now we can create our storm topology.</p>

<p>4. Create Storm Topology</p>

<p>We now have ‘supervisor’ daemon and Kafka processes running.</p>

<p>To do real-time computation on Storm, you create what are called “topologies”. A topology is a graph of computation. Each node in a topology contains processing logic, and links between nodes indicate how data should be passed around between nodes.</p>

<p>Running a topology is straightforward. First, you package all your code and dependencies into a single jar. Then, you run a command like the following: The command below will start a new Storm Topology for TruckEvents.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>root@sandbox ~]# <span class="nb">cd</span> /opt/TruckEvents/Tutorials-master/

<span class="o">[</span>root@sandbox ~]# storm jar target/Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial2.TruckEventProcessingTopology  
</code></pre>
</div>

<p><img src="/assets/realtime-event-processing/t2-update/start_new_topology_truckevents_iot.png" alt="storm new topology" /></p>

<p>storm new topology</p>

<p>It should complete with “Finished submitting topology” as shown below.</p>

<p><img src="/assets/realtime-event-processing/t2-update/finished_submitting_topology_iot.png" alt="Screen Shot 2015-06-04 at 5.20.31 PM.png" /></p>

<p>This runs the class <code class="highlighter-rouge">TruckEventProcessingTopology</code> .The main function of the class defines the topology and submits it to Nimbus. The storm jar part takes care of connecting to Nimbus and uploading the jar.</p>

<p>Refresh the Storm UI browser window to see new Topology ‘truck-event-processor’ in the browser.</p>

<p><img src="/assets/realtime-event-processing/t2-update/truck_event_processor_topology_iot.png" alt="truck event processor new topology" /></p>

<p>5. Generate TruckEvents (Run Kafka Producer)</p>

<p>The TruckEvents producer can now be executed as we did in Tutorial #1 from the same dir:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[root@sandbox Tutorials-master]# java -cp target/Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial1.TruckEventsProducer sandbox.hortonworks.com:6667 sandbox.hortonworks.com:2181  
</code></pre>
</div>

<p><img src="/assets/realtime-event-processing/t2-update/generate_truckevents_iot.png" alt="Truck Events Producer" /></p>

<p>Truck Events Producer</p>

<p>Go back to the Storm UI and click on <strong>truck-event-processor</strong> topology to drill into it.  Under Spouts, after 2 to 3 minutes, you should see that numbers of emitted and transferred tuples is increasing which shows that the messages are processed in real time by Spout</p>

<p><img src="/assets/realtime-event-processing/t2-update/spouts_bolts_iot.png" alt="" /></p>

<p>kafkaSpout count</p>

<p>You can press Control-C to stop the Kafka producer (i.e keep Control key pressed and then press C)</p>

<p><strong>Under Topology Visualization in the Storm UI</strong>: You should be able to see the topology youcreated by clicking the <strong>Show Visualization</strong> button.</p>

<p><img src="/assets/realtime-event-processing/t2-update/topology_visualization_iot.png" alt="" /></p>

<ul>
  <li>You can also keep track of several statistics of Spouts and Bolts. For instance, to find Spouts Statistics, click on kafkaSpout located in the Spouts section. You see the following screen:</li>
</ul>

<p><img src="/assets/realtime-event-processing/t2-update/spouts_statistics_iot.png" alt="" /></p>

<blockquote>
  <p>Spouts Statistics</p>
</blockquote>

<p><img src="/assets/realtime-event-processing/t2-update/bolt_statistics_iot.png" alt="" /></p>

<blockquote>
  <p>Bolts Statistics</p>
</blockquote>

<h2 id="step-3-code-description-a-idcode-review-lab2a">Step 3: Code description <a id="code-review-lab2"></a></h2>

<p>Let us review the code used in this tutorial. The source files are under the <code class="highlighter-rouge">/opt/TruckEvents/Tutorials-master/src/main/java/com/hortonworks/tutorials/tutorial2/</code> folder.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>root@sandbox Tutorials-master]# ls -l src/main/java/com/hortonworks/tutorials/tutorial2/    
total 16    
-rw-r--r-- 1 root root  861 Jul 24 23:34 BaseTruckEventTopology.java    
-rw-r--r-- 1 root root 1205 Jul 24 23:34 LogTruckEventsBolt.java    
-rw-r--r-- 1 root root 2777 Jul 24 23:34 TruckEventProcessingTopology.java    
-rw-r--r-- 1 root root 2233 Jul 24 23:34 TruckScheme.java    
</code></pre>
</div>

<h4 id="basetruckeventtopologyjava">BaseTruckEventTopology.java</h4>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="n">topologyConfig</span><span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="n">ClassLoader</span><span class="o">.</span><span class="na">getSystemResourceAsStream</span><span class="o">(</span><span class="n">configFileLocation</span><span class="o">));</span>  
</code></pre>
</div>

<p>Is the base class, where the topology configurations is initialized from the <code class="highlighter-rouge">/resource/truck_event_topology.properties</code> files.</p>

<h4 id="truckeventprocessingtopologyjava">TruckEventProcessingTopology.java</h4>

<p>This is the storm topology configuration class, where the Kafka spout and LogTruckevent Bolts are initialized. In the following method the Kafka spout is configured.</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kd">private</span> <span class="n">SpoutConfig</span> <span class="nf">constructKafkaSpoutConf</span><span class="o">()</span> <span class="err"> </span>  
<span class="o">{</span>  
<span class="err">…</span> <span class="err"> </span>  
    <span class="n">SpoutConfig</span> <span class="n">spoutConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SpoutConfig</span><span class="o">(</span><span class="n">hosts</span><span class="o">,</span> <span class="n">topic</span><span class="o">,</span> <span class="n">zkRoot</span><span class="o">,</span> <span class="n">consumerGroupId</span><span class="o">);</span> <span class="err"> </span>  
<span class="err">…</span>  
        <span class="n">spoutConfig</span><span class="o">.</span><span class="na">scheme</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SchemeAsMultiScheme</span><span class="o">(</span><span class="k">new</span> <span class="n">TruckScheme</span><span class="o">());</span>  

    <span class="k">return</span> <span class="n">spoutConfig</span><span class="o">;</span> <span class="err"> </span>  
<span class="o">}</span>  
</code></pre>
</div>

<p>A logging bolt prints the message from the Kafka spout. The logging bolt was created for debugging purposes just for this tutorial.</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kd">public</span> <span class="kt">void</span> <span class="nf">configureLogTruckEventBolt</span><span class="o">(</span><span class="n">TopologyBuilder</span> <span class="n">builder</span><span class="o">)</span>
<span class="o">{</span>
    <span class="n">LogTruckEventsBolt</span> <span class="n">logBolt</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LogTruckEventsBolt</span><span class="o">();</span>

    <span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="n">LOG_TRUCK_BOLT_ID</span><span class="o">,</span> <span class="n">logBolt</span><span class="o">).</span><span class="na">globalGrouping</span><span class="o">(</span><span class="n">KAFKA_SPOUT_ID</span><span class="o">);</span>
<span class="o">}</span>
</code></pre>
</div>

<p>The topology is built and submitted in the following method;</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kd">private</span> <span class="kt">void</span> <span class="nf">buildAndSubmit</span><span class="o">()</span> <span class="kd">throws</span> <span class="n">Exception</span>
<span class="o">{</span>
    <span class="o">...</span>

    <span class="n">StormSubmitter</span><span class="o">.</span><span class="na">submitTopology</span><span class="o">(</span><span class="s">"truck-event-processor"</span><span class="o">,</span>

    <span class="n">conf</span><span class="o">,</span> <span class="n">builder</span><span class="o">.</span><span class="na">createTopology</span><span class="o">());</span>
<span class="o">}</span>
</code></pre>
</div>

<h4 id="truckschemejava">TruckScheme.java</h4>

<p>Is the deserializer provided to the kafka spout to deserialize kafka byte message stream to Values objects.</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kd">public</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Object</span><span class="o">&gt;</span> <span class="nf">deserialize</span><span class="o">(</span><span class="kt">byte</span><span class="o">[]</span> <span class="n">bytes</span><span class="o">)</span> <span class="err"> </span>  
<span class="o">{</span>  
        <span class="k">try</span> <span class="err"> </span>  
        <span class="o">{</span>  
            <span class="n">String</span> <span class="n">truckEvent</span> <span class="o">=</span> <span class="k">new</span> <span class="n">String</span><span class="o">(</span><span class="n">bytes</span><span class="o">,</span> <span class="s">"UTF-8"</span><span class="o">);</span> <span class="err"> </span>  
            <span class="n">String</span><span class="o">[]</span> <span class="n">pieces</span> <span class="o">=</span> <span class="n">truckEvent</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">"\\|"</span><span class="o">);</span>  

            <span class="n">Timestamp</span> <span class="n">eventTime</span> <span class="o">=</span> <span class="n">Timestamp</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">pieces</span><span class="o">[</span><span class="mi">0</span><span class="o">]);</span> <span class="err"> </span>  
            <span class="n">String</span> <span class="n">truckId</span> <span class="o">=</span> <span class="n">pieces</span><span class="o">[</span><span class="mi">1</span><span class="o">];</span> <span class="err"> </span>  
            <span class="n">String</span> <span class="n">driverId</span> <span class="o">=</span> <span class="n">pieces</span><span class="o">[</span><span class="mi">2</span><span class="o">];</span> <span class="err"> </span>  
            <span class="n">String</span> <span class="n">eventType</span> <span class="o">=</span> <span class="n">pieces</span><span class="o">[</span><span class="mi">3</span><span class="o">];</span> <span class="err"> </span>  
            <span class="n">String</span> <span class="n">longitude</span><span class="o">=</span> <span class="n">pieces</span><span class="o">[</span><span class="mi">4</span><span class="o">];</span> <span class="err"> </span>  
            <span class="n">String</span> <span class="n">latitude</span> <span class="err"> </span><span class="o">=</span> <span class="n">pieces</span><span class="o">[</span><span class="mi">5</span><span class="o">];</span> <span class="err"> </span>  
            <span class="k">return</span> <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="n">cleanup</span><span class="o">(</span><span class="n">driverId</span><span class="o">),</span> <span class="n">cleanup</span><span class="o">(</span><span class="n">truckId</span><span class="o">),</span> <span class="err"> </span>  
                                    <span class="n">eventTime</span><span class="o">,</span> <span class="n">cleanup</span><span class="o">(</span><span class="n">eventType</span><span class="o">),</span> <span class="n">cleanup</span><span class="o">(</span><span class="n">longitude</span><span class="o">),</span> <span class="n">cleanup</span><span class="o">(</span><span class="n">latitude</span><span class="o">));</span>  
        <span class="o">}</span>
        
        <span class="k">catch</span> <span class="o">(</span><span class="n">UnsupportedEncodingException</span> <span class="n">e</span><span class="o">)</span> <span class="err"> </span>  
        <span class="o">{</span>  
                       <span class="n">LOG</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="n">e</span><span class="o">);</span> <span class="err"> </span>  
                       <span class="k">throw</span> <span class="k">new</span> <span class="nf">RuntimeException</span><span class="o">(</span><span class="n">e</span><span class="o">);</span> <span class="err"> </span>  
        <span class="o">}</span>  
<span class="o">}</span>  
</code></pre>
</div>

<h4 id="logtruckeventsboltjava">LogTruckEventsBolt.java</h4>

<p>LogTruckEvent spout logs the kafka message received from the kafka spout to the log files under <code class="highlighter-rouge">/var/log/storm/worker-*.log</code></p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kd">public</span> <span class="kt">void</span> <span class="nf">execute</span><span class="o">(</span><span class="n">Tuple</span> <span class="n">tuple</span><span class="o">)</span>
<span class="o">{</span>
    <span class="n">LOG</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="n">tuple</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="n">TruckScheme</span><span class="o">.</span><span class="na">FIELD_DRIVER_ID</span><span class="o">)</span> <span class="o">+</span> <span class="s">","</span> <span class="o">+</span>

    <span class="n">tuple</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="n">TruckScheme</span><span class="o">.</span><span class="na">FIELD_TRUCK_ID</span><span class="o">)</span> <span class="o">+</span> <span class="s">","</span> <span class="o">+</span>

    <span class="n">tuple</span><span class="o">.</span><span class="na">getValueByField</span><span class="o">(</span><span class="n">TruckScheme</span><span class="o">.</span><span class="na">FIELD_EVENT_TIME</span><span class="o">)</span> <span class="o">+</span> <span class="s">","</span> <span class="o">+</span>

    <span class="n">tuple</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="n">TruckScheme</span><span class="o">.</span><span class="na">FIELD_EVENT_TYPE</span><span class="o">)</span> <span class="o">+</span> <span class="s">","</span> <span class="o">+</span>

    <span class="n">tuple</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="n">TruckScheme</span><span class="o">.</span><span class="na">FIELD_LATITUDE</span><span class="o">)</span> <span class="o">+</span> <span class="s">","</span> <span class="o">+</span>

    <span class="n">tuple</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="n">TruckScheme</span><span class="o">.</span><span class="na">FIELD_LONGITUDE</span><span class="o">));</span>
<span class="o">}</span>
</code></pre>
</div>

<h2 id="conclusion">Conclusion</h2>

<p>In this tutorial we have learned to capture data from Kafka Producer into Storm Spout. This data can now be processed in real time. In our next Tutorial, using Storm Bolt, you will see how to store data into multiple sources for persistence.</p>

<h3 id="appendix-a-compile-storm-topology-from-command-line-a-idappendix-a-compile-storm-topology-lab2a">Appendix A: Compile Storm topology from command line <a id="appendix-a-compile-storm-topology-lab2"></a></h3>

<p>Compile the code using Maven after downloading a new data file or on completing any changes to the code under <code class="highlighter-rouge">/opt/TruckEvents/Tutorials-master/src directory</code>.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>    <span class="o">[</span>root@sandbox ~]# <span class="nb">cd</span> /opt/TruckEvents/Tutorials-master/    
    <span class="o">[</span>root@sandbox ~]# mvn clean package  
</code></pre>
</div>

<p><img src="/assets/realtime-event-processing/t1-update/maven_clean_package_iot.png" alt="mvn clean package" /></p>

<p><img src="/assets/realtime-event-processing/t1-update/build_success_maven_iot.png" alt="mvn build success" /></p>

<p>We now have a successfully compiled the code.</p>

<h3 id="appendix-b-enable-remote-desktop-on-sandbox-and-setting-up-storm-topology-as-eclipse-project-a-idappendix-b-setup-storm-topology-eclipse-project-lab2a">Appendix B: Enable remote desktop on sandbox and setting up Storm topology as Eclipse project <a id="appendix-b-setup-storm-topology-eclipse-project-lab2"></a></h3>

<ol>
  <li>Setup Ambari VNC service on the sandbox to enable remote desktop via VNC and install eclipse using steps here <a href="https://github.com/hortonworks-gallery/ambari-vnc-service%23setup-vnc-service">https://github.com/hortonworks-gallery/ambari-vnc-service#setup-vnc-service</a>
2.  Import code as Eclipse project using steps here:</li>
</ol>

<p><a href="https://github.com/hortonworks-gallery/ambari-vnc-service%23getting-started-with-storm-and-maven-in-eclipse-environment">https://github.com/hortonworks-gallery/ambari-vnc-service#getting-started-with-storm-and-maven-in-eclipse-environment</a></p>

<h2 id="further-reading-a-idfurther-reading-lab2a">Further Reading <a id="further-reading-lab2"></a></h2>
<ul>
  <li><a href="http://hortonworks.com/hadoop/storm/#tutorials">Storm Tutorials</a></li>
  <li><a href="http://storm.apache.org/documentation.html">Getting Started with Apache Storm</a></li>
  <li><a href="http://hortonworks.com/hadoop/storm/">Apache Storm</a></li>
</ul>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-220.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-220&topics=hdp-2.4.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Ingesting and Processing Realtime Events with Apache Storm</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-220</strong> and <strong>hdp-2.4.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
