

<div class="tutorial-content">
  <h2 id="introduction">Introduction</h2>

<p>Apache Falcon simplifies the configuration of data motion with: replication; lifecycle management; lineage and traceability. This provides data governance consistency across Hadoop components.</p>

<h2 id="scenario">Scenario</h2>

<p>In this tutorial we will walk through a scenario where email data gets processed on multiple HDP 2.2 clusters around the country then gets backed up hourly on a cloud hosted cluster . In our example:</p>

<ul>
  <li>This cluster is hosted on Windows Azure.</li>
  <li>Data arrives from all the West Coast production servers. The input data feeds are often late for up to 4 hrs.</li>
</ul>

<p>The goal is to clean the raw data to remove sensitive information like credit card numbers and make it available to our marketing data science team for customer churn analysis.</p>

<p>To simulate this scenario, we have a pig script grabbing the freely available Enron emails from the internet and feeding it into the pipeline.</p>

<p><img src="/assets/hdp-azure-falcon-backup/arch.png" alt="" /></p>

<h2 id="prerequisite">Prerequisite</h2>

<ul>
  <li>A cluster with Apache Hadoop 2.2 configured</li>
  <li>A cluster with Apache Falcon configured</li>
</ul>

<p>The easiest way to meet the above prerequisites is to download the <a href="http://hortonworks.com/downloads">HDP Sandbox</a></p>

<h2 id="steps-for-the-scenario">Steps for the Scenario</h2>

<ol>
  <li>Create cluster specification XML file</li>
  <li>Create feed (aka dataset) specification XML file
    <ul>
      <li>Reference cluster specification</li>
    </ul>
  </li>
  <li>Create the process specification XML file
    <ul>
      <li>Reference cluster specification – defines where the process runs</li>
      <li>Reference feed specification – defines the datasets that the process manipulates</li>
    </ul>
  </li>
</ol>

<p>We have already created the necessary xml files. In this step we are going to download the specifications and use them to define the topology and submit the storm job.</p>

<h3 id="downloading-and-staging-the-dataset">Downloading and staging the dataset</h3>

<p>Now let’s stage the dataset using the commandline. Although we perform many of these file operations below using the command line, you can also do the same with the <code class="highlighter-rouge">HDFS Files  View</code> in Ambari.</p>

<p>First SSH into the Hortonworks Sandbox with the command:</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot_2015-04-13_07_58_43.png?dl=1" alt="" /></p>

<p>The default password is <code class="highlighter-rouge">hadoop</code></p>

<p>Then login as user <code class="highlighter-rouge">hdfs</code></p>

<div class="highlighter-rouge"><pre class="highlight"><code>su - hdfs
</code></pre>
</div>

<p>Then download the file falcon.zip with the following command”</p>

<div class="highlighter-rouge"><pre class="highlight"><code>wget http://hortonassets.s3.amazonaws.com/tutorial/falcon/falcon.zip
</code></pre>
</div>

<p>and then unzip with the command</p>

<div class="highlighter-rouge"><pre class="highlight"><code>unzip falcon.zip
</code></pre>
</div>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-10%2018.39.50.png?dl=1" alt="" /></p>

<p>Now let’s give ourselves permission to upload files</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -chmod -R 777 /user/ambari-qa
</code></pre>
</div>

<p>then let’s create a folder <code class="highlighter-rouge">falcon</code> under <code class="highlighter-rouge">ambari-qa</code> with the command</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -mkdir /user/ambari-qa/falcon
</code></pre>
</div>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-25%2018.24.59.png?dl=1" alt="" /></p>

<p>Now let’s upload the decompressed folder with the command</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -copyFromLocal demo /user/ambari-qa/falcon/
</code></pre>
</div>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.05.45.png?dl=1" alt="" /></p>

<h3 id="setting-up-the-destination-storage-on-microsoft-azure">Setting up the destination storage on Microsoft Azure</h3>

<p>Login to the Windows Azure portal at <a href="http://manage.windowsazure.com">http://manage.windowsazure.com</a></p>

<p><img src="/assets/hdp-azure-falcon-backup/image13.png" alt="" /></p>

<p>Create a storage account</p>

<p><img src="/assets/hdp-azure-falcon-backup/image16.png" alt="" /></p>

<p>Wait for the storage account to be provisioned</p>

<p><img src="/assets/hdp-azure-falcon-backup/image19.png" alt="" /></p>

<p>Copy the access key and the account name in a text document. We will use the access key and the account name in later steps</p>

<p><img src="/assets/hdp-azure-falcon-backup/image22.png" alt="" /></p>

<p>The other information you will want to note down is the blob endpoint of the storage account we just created</p>

<p><img src="/assets/hdp-azure-falcon-backup/image25.png" alt="" /></p>

<p>Click on the <code class="highlighter-rouge">Containers</code> tab and create a new container called <code class="highlighter-rouge">myfirstcontainer</code>.</p>

<p><img src="/assets/hdp-azure-falcon-backup/image26.png" alt="" /></p>

<h3 id="configuring-access-to-azure-blob-store-from-hadoop">Configuring access to Azure Blob store from Hadoop</h3>

<p>Login to Ambari – http://127.0.0.1:8080 with the credentials <code class="highlighter-rouge">admin</code> and <code class="highlighter-rouge">admin</code>.</p>

<p><img src="/assets/hdp-azure-falcon-backup/image27.png" alt="" /></p>

<p>Then click on HDFS from the bar on the left and then select the <code class="highlighter-rouge">Configs</code> tab.</p>

<p><img src="/assets/hdp-azure-falcon-backup/image28.png" alt="" /></p>

<p>Scroll down to the bottom of the page to the <code class="highlighter-rouge">Custom hdfs-site</code> section and click on <code class="highlighter-rouge">Add  property...</code></p>

<p><img src="/assets/hdp-azure-falcon-backup/image31.png" alt="" /></p>

<p>In the <code class="highlighter-rouge">Add  Property</code> dialog, the key name will start with <code class="highlighter-rouge">fs.azure.account.key.</code> followed by your blob endpoint that you noted down in a previous step. The value will be the Azure storage key that you noted down in a previous step. Once you have filled in the values click the <code class="highlighter-rouge">Add</code> button:</p>

<p><img src="/assets/hdp-azure-falcon-backup/image34.png" alt="" /></p>

<p>Once you are back out of the new key dialog you will have to <code class="highlighter-rouge">Save</code> it by clicking on the green <code class="highlighter-rouge">Save</code> button:</p>

<p><img src="/assets/hdp-azure-falcon-backup/image31.png" alt="" /></p>

<p>Then restart all the service by clicking on the orange <code class="highlighter-rouge">Restart</code> button:</p>

<p><img src="/assets/hdp-azure-falcon-backup/image36.png" alt="" /></p>

<p>Wait for all the restart to complete</p>

<p><img src="/assets/hdp-azure-falcon-backup/image38.png" alt="" /></p>

<p>Now let’s test if we can access our container on the Azure Blob Store.</p>

<p>SSH in to the VM:</p>

<p><code class="highlighter-rouge">ssh root@127.0.0.1  -p 2222;</code></p>

<p>The password is <code class="highlighter-rouge">hadoop</code></p>

<p><code class="highlighter-rouge">hdfs dfs -ls -R wasb://myfirstcontainer@saptak.blob.core.windows.net/</code></p>

<p>Issue the command from our cluster on the SSH’d terminal</p>

<p><img src="/assets/hdp-azure-falcon-backup/image40.png" alt="" /></p>

<h3 id="creating-the-cluster-entities">Creating the cluster entities</h3>

<p>Before creating the cluster entities, we need to create the directories on HDFS representing the two clusters that we are going to define, namely <code class="highlighter-rouge">primaryCluster</code> and <code class="highlighter-rouge">backupCluster</code>.</p>

<p>Use <code class="highlighter-rouge">hadoop fs -mkdir</code> commands to create the directories <code class="highlighter-rouge">/apps/falcon/primaryCluster</code> and <code class="highlighter-rouge">/apps/falcon/backupCluster</code> directories on HDFS.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -mkdir /apps/falcon/primaryCluster
hadoop fs -mkdir /apps/falcon/backupCluster
</code></pre>
</div>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.29.58.png?dl=1" alt="" /></p>

<p>Further create directories called <code class="highlighter-rouge">staging</code> inside each of the directories we created above:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -mkdir /apps/falcon/primaryCluster/staging
hadoop fs -mkdir /apps/falcon/backupCluster/staging
</code></pre>
</div>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.31.37.png?dl=1" alt="" /></p>

<p>Next we will need to create the <code class="highlighter-rouge">working</code> directories for <code class="highlighter-rouge">primaryCluster</code> and <code class="highlighter-rouge">backupCluster</code></p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -mkdir /apps/falcon/primaryCluster/working
hadoop fs -mkdir /apps/falcon/backupCluster/working
</code></pre>
</div>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.36.12.png?dl=1" alt="" /></p>

<p>Finally you need to set the proper permissions on the staging/working directories:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -chmod 777 /apps/falcon/primaryCluster/staging
hadoop fs -chmod 755 /apps/falcon/primaryCluster/working
hadoop fs -chmod 777 /apps/falcon/backupCluster/staging
hadoop fs -chmod 755 /apps/falcon/backupCluster/working
hadoop fs –chown –R falcon /apps/falcon/*
</code></pre>
</div>

<p>Let’s open the Falcon Web UI. You can easily launch the Falcon Web UI from Ambari:</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-19%2016.31.12.png?dl=1" alt="" /></p>

<p>You can also navigate to the Falcon Web UI directly on our browser. The Falcon UI is by default at port 15000. The default username is <code class="highlighter-rouge">ambari-qa</code> and the password is <code class="highlighter-rouge">admin</code>.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.45.40.png?dl=1" alt="" /></p>

<p>This UI allows us to create and manage the various entities like Cluster, Feed, Process and Mirror. Each of these entities are represented by a XML file which you either directly upload or generate by filling up the various fields.</p>

<p>You can also search for existing entities and then edit, change state, etc.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.46.23.png?dl=1" alt="" /></p>

<p>Let’s first create a couple of cluster entities. To create a cluster entity click on the <code class="highlighter-rouge">Cluster</code> button on the top.</p>

<p>Then click on the <code class="highlighter-rouge">edit</code> button over XML Preview area on the right hand side of the screen and replace the XML content with the XML document below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span>
<span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"primaryCluster"</span> <span class="na">description=</span><span class="s">"this is primary cluster"</span> <span class="na">colo=</span><span class="s">"primaryColo"</span> <span class="na">xmlns=</span><span class="s">"uri:falcon:cluster:0.1"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;tags&gt;</span>primaryKey=primaryValue<span class="nt">&lt;/tags&gt;</span>
    <span class="nt">&lt;interfaces&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"readonly"</span> <span class="na">endpoint=</span><span class="s">"hftp://sandbox.hortonworks.com:50070"</span> <span class="na">version=</span><span class="s">"2.2.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"write"</span> <span class="na">endpoint=</span><span class="s">"hdfs://sandbox.hortonworks.com:8020"</span> <span class="na">version=</span><span class="s">"2.2.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"execute"</span> <span class="na">endpoint=</span><span class="s">"sandbox.hortonworks.com:8050"</span> <span class="na">version=</span><span class="s">"2.2.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"workflow"</span> <span class="na">endpoint=</span><span class="s">"http://sandbox.hortonworks.com:11000/oozie/"</span> <span class="na">version=</span><span class="s">"4.0.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"messaging"</span> <span class="na">endpoint=</span><span class="s">"tcp://sandbox.hortonworks.com:61616?daemon=true"</span> <span class="na">version=</span><span class="s">"5.1.6"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/interfaces&gt;</span>
    <span class="nt">&lt;locations&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">name=</span><span class="s">"staging"</span> <span class="na">path=</span><span class="s">"/apps/falcon/primaryCluster/staging"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">name=</span><span class="s">"temp"</span> <span class="na">path=</span><span class="s">"/tmp"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">name=</span><span class="s">"working"</span> <span class="na">path=</span><span class="s">"/apps/falcon/primaryCluster/working"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/locations&gt;</span>
    <span class="nt">&lt;ACL</span> <span class="na">owner=</span><span class="s">"ambari-qa"</span> <span class="na">group=</span><span class="s">"users"</span> <span class="na">permission=</span><span class="s">"0x755"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;properties&gt;</span>
        <span class="nt">&lt;property</span> <span class="na">name=</span><span class="s">"test"</span> <span class="na">value=</span><span class="s">"value1"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/properties&gt;</span>
<span class="nt">&lt;/cluster&gt;</span>
</code></pre>
</div>

<p>Click <code class="highlighter-rouge">Finish</code> on top of the XML Preview area to save the XML.<br />
<img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.49.25.png?dl=1" alt="" /></p>

<p>Falcon UI should have automatically parsed out the values from the XML and populated in the right fields. Once you have verified that these are the correct values press <code class="highlighter-rouge">Next</code>.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.50.01.png?dl=1" alt="" /></p>

<p>Click <code class="highlighter-rouge">Save</code> to persist the entity.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.50.18.png?dl=1" alt="" /></p>

<p>Similarly, we will create the <code class="highlighter-rouge">backupCluster</code> entity. Again click on <code class="highlighter-rouge">Cluster</code> button on the top to open up the form to create the cluster entity.</p>

<p>Then click on the <code class="highlighter-rouge">edit</code> button over XML Preview area on the right hand side of the screen and replace the XML content with the XML document below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span>
<span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"backupCluster"</span> <span class="na">description=</span><span class="s">"this is backup colo"</span> <span class="na">colo=</span><span class="s">"backupColo"</span> <span class="na">xmlns=</span><span class="s">"uri:falcon:cluster:0.1"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;tags&gt;</span>backupTag=backupTagValue<span class="nt">&lt;/tags&gt;</span>
    <span class="nt">&lt;interfaces&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"readonly"</span> <span class="na">endpoint=</span><span class="s">"hftp://sandbox.hortonworks.com:50070"</span> <span class="na">version=</span><span class="s">"2.2.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"write"</span> <span class="na">endpoint=</span><span class="s">"hdfs://sandbox.hortonworks.com:8020"</span> <span class="na">version=</span><span class="s">"2.2.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"execute"</span> <span class="na">endpoint=</span><span class="s">"sandbox.hortonworks.com:8050"</span> <span class="na">version=</span><span class="s">"2.2.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"workflow"</span> <span class="na">endpoint=</span><span class="s">"http://sandbox.hortonworks.com:11000/oozie/"</span> <span class="na">version=</span><span class="s">"4.0.0"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;interface</span> <span class="na">type=</span><span class="s">"messaging"</span> <span class="na">endpoint=</span><span class="s">"tcp://sandbox.hortonworks.com:61616?daemon=true"</span> <span class="na">version=</span><span class="s">"5.1.6"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/interfaces&gt;</span>
    <span class="nt">&lt;locations&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">name=</span><span class="s">"staging"</span> <span class="na">path=</span><span class="s">"/apps/falcon/backupCluster/staging"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">name=</span><span class="s">"temp"</span> <span class="na">path=</span><span class="s">"/tmp"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">name=</span><span class="s">"working"</span> <span class="na">path=</span><span class="s">"/apps/falcon/backupCluster/working"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/locations&gt;</span>
    <span class="nt">&lt;ACL</span> <span class="na">owner=</span><span class="s">"ambari-qa"</span> <span class="na">group=</span><span class="s">"users"</span> <span class="na">permission=</span><span class="s">"0x755"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;properties&gt;</span>
        <span class="nt">&lt;property</span> <span class="na">name=</span><span class="s">"key1"</span> <span class="na">value=</span><span class="s">"val1"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/properties&gt;</span>
<span class="nt">&lt;/cluster&gt;</span>
</code></pre>
</div>

<p>Click <code class="highlighter-rouge">Finish</code> on top of the XML Preview area to save the XML and then the <code class="highlighter-rouge">Next</code> button to verify the values.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.51.14.png?dl=1" alt="" /></p>

<p>Click <code class="highlighter-rouge">Save</code> to persist the <code class="highlighter-rouge">backupCluster</code> entity.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-07%2010.51.33.png?dl=1" alt="" /></p>

<h3 id="defining-the-rawemailfeed-entity">Defining the rawEmailFeed entity</h3>

<p>To create a feed entity click on the <code class="highlighter-rouge">Feed</code> button on the top of the main page on the Falcon Web UI.</p>

<p>Then click on the edit button over XML Preview area on the right hand side of the screen and replace the XML content with the XML document below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span>
<span class="nt">&lt;feed</span> <span class="na">name=</span><span class="s">"rawEmailFeed"</span> <span class="na">description=</span><span class="s">"Raw customer email feed"</span> <span class="na">xmlns=</span><span class="s">"uri:falcon:feed:0.1"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;tags&gt;</span>externalSystem=USWestEmailServers<span class="nt">&lt;/tags&gt;</span>
    <span class="nt">&lt;groups&gt;</span>churnAnalysisDataPipeline<span class="nt">&lt;/groups&gt;</span>
    <span class="nt">&lt;frequency&gt;</span>hours(1)<span class="nt">&lt;/frequency&gt;</span>
    <span class="nt">&lt;timezone&gt;</span>UTC<span class="nt">&lt;/timezone&gt;</span>
    <span class="nt">&lt;late-arrival</span> <span class="na">cut-off=</span><span class="s">"hours(1)"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;clusters&gt;</span>
        <span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"primaryCluster"</span> <span class="na">type=</span><span class="s">"source"</span><span class="nt">&gt;</span>
            <span class="nt">&lt;validity</span> <span class="na">start=</span><span class="s">"2015-07-22T01:00Z"</span> <span class="na">end=</span><span class="s">"2015-07-22T10:00Z"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;retention</span> <span class="na">limit=</span><span class="s">"days(90)"</span> <span class="na">action=</span><span class="s">"delete"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;/cluster&gt;</span>
    <span class="nt">&lt;/clusters&gt;</span>
    <span class="nt">&lt;locations&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"data"</span> <span class="na">path=</span><span class="s">"/user/ambari-qa/falcon/demo/primary/input/enron/${YEAR}-${MONTH}-${DAY}-${HOUR}"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"stats"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"meta"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/locations&gt;</span>
    <span class="nt">&lt;ACL</span> <span class="na">owner=</span><span class="s">"ambari-qa"</span> <span class="na">group=</span><span class="s">"users"</span> <span class="na">permission=</span><span class="s">"0x755"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;schema</span> <span class="na">location=</span><span class="s">"/none"</span> <span class="na">provider=</span><span class="s">"/none"</span><span class="nt">/&gt;</span>
<span class="nt">&lt;/feed&gt;</span>
</code></pre>
</div>

<p>Click <code class="highlighter-rouge">Finish</code> on the top of the XML Preview area</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.09.14.png?dl=1" alt="" /></p>

<p>Falcon UI should have automatically parsed out the values from the XML and populated in the right fields. Once you have verified that these are the correct values press <code class="highlighter-rouge">Next</code>.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.14.21.png?dl=1" alt="" /></p>

<p>On the Clusters page ensure you modify the validity to a time slice which is in the very near future.</p>

<p>Click <code class="highlighter-rouge">Next</code></p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.15.35.png?dl=1" alt="" /></p>

<p>Save the feed</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.16.01.png?dl=1" alt="" /></p>

<h3 id="defining-the-rawemailingestprocess-entity">Defining the rawEmailIngestProcess entity</h3>

<p>Now lets define the <code class="highlighter-rouge">rawEmailIngestProcess</code>.</p>

<p>To create a process entity click on the <code class="highlighter-rouge">Process</code> button on the top of the main page on the Falcon Web UI.</p>

<p>Then click on the edit button over XML Preview area on the right hand side of the screen and replace the XML content with the XML document below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span>
<span class="nt">&lt;process</span> <span class="na">name=</span><span class="s">"rawEmailIngestProcess"</span> <span class="na">xmlns=</span><span class="s">"uri:falcon:process:0.1"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;tags&gt;</span>email=testemail<span class="nt">&lt;/tags&gt;</span>
    <span class="nt">&lt;clusters&gt;</span>
        <span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"primaryCluster"</span><span class="nt">&gt;</span>
            <span class="nt">&lt;validity</span> <span class="na">start=</span><span class="s">"2015-07-22T01:00Z"</span> <span class="na">end=</span><span class="s">"2015-07-22T10:00Z"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;/cluster&gt;</span>
    <span class="nt">&lt;/clusters&gt;</span>
    <span class="nt">&lt;parallel&gt;</span>1<span class="nt">&lt;/parallel&gt;</span>
    <span class="nt">&lt;order&gt;</span>FIFO<span class="nt">&lt;/order&gt;</span>
    <span class="nt">&lt;frequency&gt;</span>hours(1)<span class="nt">&lt;/frequency&gt;</span>
    <span class="nt">&lt;timezone&gt;</span>UTC<span class="nt">&lt;/timezone&gt;</span>
    <span class="nt">&lt;outputs&gt;</span>
        <span class="nt">&lt;output</span> <span class="na">name=</span><span class="s">"output"</span> <span class="na">feed=</span><span class="s">"rawEmailFeed"</span> <span class="na">instance=</span><span class="s">"now(0,0)"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/outputs&gt;</span>
    <span class="nt">&lt;workflow</span> <span class="na">name=</span><span class="s">"emailIngestWorkflow"</span> <span class="na">version=</span><span class="s">"4.0.1"</span> <span class="na">engine=</span><span class="s">"oozie"</span> <span class="na">path=</span><span class="s">"/user/ambari-qa/falcon/demo/apps/ingest/fs"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;retry</span> <span class="na">policy=</span><span class="s">"exp-backoff"</span> <span class="na">delay=</span><span class="s">"minutes(3)"</span> <span class="na">attempts=</span><span class="s">"3"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;ACL</span> <span class="na">owner=</span><span class="s">"ambari-qa"</span> <span class="na">group=</span><span class="s">"users"</span> <span class="na">permission=</span><span class="s">"0x755"</span><span class="nt">/&gt;</span>
<span class="nt">&lt;/process&gt;</span>
</code></pre>
</div>

<p>Click <code class="highlighter-rouge">Finish</code> on the top of the XML Preview area</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.17.01.png?dl=1" alt="" /></p>

<p>Accept the default values and click next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.17.19.png?dl=1" alt="" /></p>

<p>On the Clusters page ensure you modify the validity to a time slice which is in the very near future and then click next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.18.02.png?dl=1" alt="" /></p>

<p>Accept the default values and click Next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.18.15.png?dl=1" alt="" /></p>

<p>Let’s <code class="highlighter-rouge">Save</code> the process.</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.18.37.png?dl=1" alt="" /></p>

<h3 id="defining-the-cleansedemailfeed">Defining the cleansedEmailFeed</h3>

<p>Again, to create a feed entity click on the <code class="highlighter-rouge">Feed</code> button on the top of the main page on the Falcon Web UI.</p>

<p>Then click on the edit button over XML Preview area on the right hand side of the screen and replace the XML content with the XML document below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span>
<span class="nt">&lt;feed</span> <span class="na">name=</span><span class="s">"cleansedEmailFeed"</span> <span class="na">description=</span><span class="s">"Cleansed customer emails"</span> <span class="na">xmlns=</span><span class="s">"uri:falcon:feed:0.1"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;tags&gt;</span>cleanse=cleaned<span class="nt">&lt;/tags&gt;</span>
    <span class="nt">&lt;groups&gt;</span>churnAnalysisDataPipeline<span class="nt">&lt;/groups&gt;</span>
    <span class="nt">&lt;frequency&gt;</span>hours(1)<span class="nt">&lt;/frequency&gt;</span>
    <span class="nt">&lt;timezone&gt;</span>UTC<span class="nt">&lt;/timezone&gt;</span>
    <span class="nt">&lt;late-arrival</span> <span class="na">cut-off=</span><span class="s">"hours(4)"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;clusters&gt;</span>
        <span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"primaryCluster"</span> <span class="na">type=</span><span class="s">"source"</span><span class="nt">&gt;</span>
            <span class="nt">&lt;validity</span> <span class="na">start=</span><span class="s">"2015-07-22T01:00Z"</span> <span class="na">end=</span><span class="s">"2015-07-22T10:00Z"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;retention</span> <span class="na">limit=</span><span class="s">"hours(90)"</span> <span class="na">action=</span><span class="s">"delete"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;locations&gt;</span>
                <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"data"</span> <span class="na">path=</span><span class="s">"/user/ambari-qa/falcon/demo/primary/processed/enron/${YEAR}-${MONTH}-${DAY}-${HOUR}"</span><span class="nt">/&gt;</span>
                <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"stats"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
                <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"meta"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;/locations&gt;</span>
        <span class="nt">&lt;/cluster&gt;</span>
        <span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"backupCluster"</span> <span class="na">type=</span><span class="s">"target"</span><span class="nt">&gt;</span>
            <span class="nt">&lt;validity</span> <span class="na">start=</span><span class="s">"2015-07-22T01:00Z"</span> <span class="na">end=</span><span class="s">"2015-07-22T10:00Z"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;retention</span> <span class="na">limit=</span><span class="s">"hours(90)"</span> <span class="na">action=</span><span class="s">"delete"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;locations&gt;</span>
                <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"data"</span> <span class="na">path=</span><span class="s">"/falcon/demo/bcp/processed/enron/${YEAR}-${MONTH}-${DAY}-${HOUR}"</span><span class="nt">/&gt;</span>
                <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"stats"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
                <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"meta"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
            <span class="nt">&lt;/locations&gt;</span>
        <span class="nt">&lt;/cluster&gt;</span>
    <span class="nt">&lt;/clusters&gt;</span>
    <span class="nt">&lt;locations&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"data"</span> <span class="na">path=</span><span class="s">"/user/ambari-qa/falcon/demo/processed/enron/${YEAR}-${MONTH}-${DAY}-${HOUR}"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"stats"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;location</span> <span class="na">type=</span><span class="s">"meta"</span> <span class="na">path=</span><span class="s">"/"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/locations&gt;</span>
    <span class="nt">&lt;ACL</span> <span class="na">owner=</span><span class="s">"ambari-qa"</span> <span class="na">group=</span><span class="s">"users"</span> <span class="na">permission=</span><span class="s">"0x755"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;schema</span> <span class="na">location=</span><span class="s">"/none"</span> <span class="na">provider=</span><span class="s">"/none"</span><span class="nt">/&gt;</span>
<span class="nt">&lt;/feed&gt;</span>
</code></pre>
</div>

<p>Click <code class="highlighter-rouge">Finish</code> on the top of the XML Preview area</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.35.10.png?dl=1" alt="" /></p>

<p>Accept the default values and click Next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.35.49.png?dl=1" alt="" /></p>

<p>Accept the default values and click Next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.35.58.png?dl=1" alt="" /></p>

<p>On the Clusters page ensure you modify the validity to a time slice which is in the very near future and then click Next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.36.35.png?dl=1" alt="" /></p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.37.05.png?dl=1" alt="" /></p>

<p>Accept the default values and click Save</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.37.21.png?dl=1" alt="" /></p>

<h3 id="defining-the-cleanseemailprocess">Defining the cleanseEmailProcess</h3>

<p>Now lets define the <code class="highlighter-rouge">cleanseEmailProcess</code>.</p>

<p>Again, to create a process entity click on the <code class="highlighter-rouge">Process</code> button on the top of the main page on the Falcon Web UI.</p>

<p>Then click on the edit button over XML Preview area on the right hand side of the screen and replace the XML content with the XML document below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span>
<span class="nt">&lt;process</span> <span class="na">name=</span><span class="s">"cleanseEmailProcess"</span> <span class="na">xmlns=</span><span class="s">"uri:falcon:process:0.1"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;tags&gt;</span>cleanse=yes<span class="nt">&lt;/tags&gt;</span>
    <span class="nt">&lt;clusters&gt;</span>
        <span class="nt">&lt;cluster</span> <span class="na">name=</span><span class="s">"primaryCluster"</span><span class="nt">&gt;</span>
            <span class="nt">&lt;validity</span> <span class="na">start=</span><span class="s">"2015-07-22T01:00Z"</span> <span class="na">end=</span><span class="s">"2015-07-22T10:00Z"</span><span class="nt">/&gt;</span>
        <span class="nt">&lt;/cluster&gt;</span>
    <span class="nt">&lt;/clusters&gt;</span>
    <span class="nt">&lt;parallel&gt;</span>1<span class="nt">&lt;/parallel&gt;</span>
    <span class="nt">&lt;order&gt;</span>FIFO<span class="nt">&lt;/order&gt;</span>
    <span class="nt">&lt;frequency&gt;</span>hours(1)<span class="nt">&lt;/frequency&gt;</span>
    <span class="nt">&lt;timezone&gt;</span>UTC<span class="nt">&lt;/timezone&gt;</span>
    <span class="nt">&lt;inputs&gt;</span>
        <span class="nt">&lt;input</span> <span class="na">name=</span><span class="s">"input"</span> <span class="na">feed=</span><span class="s">"rawEmailFeed"</span> <span class="na">start=</span><span class="s">"now(0,0)"</span> <span class="na">end=</span><span class="s">"now(0,0)"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/inputs&gt;</span>
    <span class="nt">&lt;outputs&gt;</span>
        <span class="nt">&lt;output</span> <span class="na">name=</span><span class="s">"output"</span> <span class="na">feed=</span><span class="s">"cleansedEmailFeed"</span> <span class="na">instance=</span><span class="s">"now(0,0)"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/outputs&gt;</span>
    <span class="nt">&lt;workflow</span> <span class="na">name=</span><span class="s">"emailCleanseWorkflow"</span> <span class="na">version=</span><span class="s">"pig-0.13.0"</span> <span class="na">engine=</span><span class="s">"pig"</span> <span class="na">path=</span><span class="s">"/user/ambari-qa/falcon/demo/apps/pig/id.pig"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;retry</span> <span class="na">policy=</span><span class="s">"exp-backoff"</span> <span class="na">delay=</span><span class="s">"minutes(5)"</span> <span class="na">attempts=</span><span class="s">"3"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;ACL</span> <span class="na">owner=</span><span class="s">"ambari-qa"</span> <span class="na">group=</span><span class="s">"users"</span> <span class="na">permission=</span><span class="s">"0x755"</span><span class="nt">/&gt;</span>
<span class="nt">&lt;/process&gt;</span>
</code></pre>
</div>

<p>Click <code class="highlighter-rouge">Finish</code> on the top of the XML Preview area</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.39.34.png?dl=1" alt="" /></p>

<p>Accept the default values and click Next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.39.53.png?dl=1" alt="" /></p>

<p>On the Clusters page ensure you modify the validity to a time slice which is in the very near future and then click Next</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.40.24.png?dl=1" alt="" /></p>

<p>Select the Input and Output Feeds as shown below and Save</p>

<p><img src="/assets/falcon-processing-pipelines/Screenshot%202015-08-11%2015.40.40.png?dl=1" alt="" /></p>

<h3 id="submit-the-entities-to-the-cluster">Submit the entities to the cluster:</h3>

<h4 id="cluster-specification">Cluster Specification</h4>

<p>Cluster specification is one per cluster.</p>

<p>See below for a sample cluster specification file.</p>

<p><img src="/assets/hdp-azure-falcon-backup/cluster-spec.png" alt="" /></p>

<p>Back to our scenario, lets submit the ‘oregon cluster’ entity to Falcon. This signifies the primary Hadoop cluster located in the Oregon data center.</p>

<p><code class="highlighter-rouge">falcon entity -type cluster -submit -file oregonCluster.xml</code></p>

<p>Then lets submit the ‘virginia cluster’ entity to Falcon. This signifies the backup Hadoop cluster located in the Virginia data center</p>

<p><code class="highlighter-rouge">falcon entity -type cluster -submit -file virginiaCluster.xml</code></p>

<p>If you view the XML file you will see how the cluster location and purpose has been captured in the XML file.</p>

<h4 id="feed-specification">Feed Specification</h4>

<p>A feed (a.k.a dataset) signifies a location of data and its associated replication policy and late arrival cut-off time.</p>

<p>See below for a sample feed (a.k.a dataset) specification file.</p>

<p><img src="/assets/hdp-azure-falcon-backup/feed-spec.png" alt="" /></p>

<p>Back to our scenario, let’s submit the source of the raw email feed. This feed signifies the raw emails that are being downloaded into the Hadoop cluster. These emails will be used by the email cleansing process.</p>

<p><code class="highlighter-rouge">falcon entity -type feed -submit -file rawEmailFeed.xml</code></p>

<p>Now let’s define the feed entity which will handle the end of the pipeline to store the cleansed email. This feed signifies the emails produced by the cleanse email process. It also takes care of replicating the cleansed email dataset to the backup cluster (virginia cluster)</p>

<p><code class="highlighter-rouge">falcon entity -type feed -submit -file cleansedEmailFeed.xml</code></p>

<h4 id="process">Process</h4>

<p>A process defines configuration for a workflow. A workflow is a directed acyclic graph(DAG) which defines the job for the workflow engine. A process definition defines the configurations required to run the workflow job. For example, process defines the frequency at which the workflow should run, the clusters on which the workflow should run, the inputs and outputs for the workflow, how the workflow failures should be handled, how the late inputs should be handled and so on.</p>

<p>Here is an example of what a process specification looks like:</p>

<p><img src="/assets/hdp-azure-falcon-backup/process-spec.png" alt="" /></p>

<p>Back to our scenario, let’s submit the ingest and the cleanse process respectively:</p>

<p>The ingest process is responsible for calling the Oozie workflow that downloads the raw emails from the web into the primary Hadoop cluster under the location specified in the rawEmailFeed.xml It also takes care of handling late data arrivals</p>

<p><code class="highlighter-rouge">falcon entity -type process -submit -file emailIngestProcess.xml</code></p>

<p>The cleanse process is responsible for calling the pig script that cleans the raw emails and produces the clean emails that are then replicated to the backup Hadoop cluster</p>

<p><code class="highlighter-rouge">falcon entity -type process -submit -file cleanseEmailProcess.xml</code></p>

<h3 id="schedule-the-falcon-entities">Schedule the Falcon entities</h3>

<p>So, all that is left now is to schedule the feeds and processes to get it going.</p>

<h4 id="ingest-the-feed">Ingest the feed</h4>

<p><code class="highlighter-rouge">falcon entity -type feed -schedule -name rawEmailFeed</code></p>

<p><code class="highlighter-rouge">falcon entity -type process -schedule -name rawEmailIngestProcess</code></p>

<h4 id="cleanse-the-emails">Cleanse the emails</h4>

<p><code class="highlighter-rouge">falcon entity -type feed -schedule -name cleansedEmailFeed</code></p>

<p><code class="highlighter-rouge">falcon entity -type process -schedule -name cleanseEmailProcess</code></p>

<h3 id="processing">Processing</h3>

<p>In a few seconds you should notice that that Falcon has started ingesting files from the internet and dumping them to new folders in HDFS.</p>

<p>In a couple of minutes you should notice a new folder called processed under which the files processed through the data pipeline are being emitted.</p>

<p>We just created an end-to-end data pipeline to process data. The power of the Apache Falcon framework is its flexibility to work with pretty much any open source or proprietary data processing products out there.</p>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-340.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-340&topics=hdp-2.4.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Incremental Backup of Data from HDP to Azure using Falcon for Disaster Recovery</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-340</strong> and <strong>hdp-2.4.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>
