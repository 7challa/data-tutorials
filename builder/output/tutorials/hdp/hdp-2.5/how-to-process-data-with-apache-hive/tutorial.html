<div class="tutorial-content">
  <h1 id="how-to-process-data-with-apache-hive">How to Process Data with Apache Hive</h1>

<h2 id="introduction">Introduction</h2>

<p>In this tutorial, we will use the <a href="https://hortonworks.com/hadoop/ambari/">Ambari</a> HDFS file view to store data files of truck drivers statistics. We will implement <a href="https://hortonworks.com/hadoop/hive/">Hive</a> queries to analyze, process and filter that data.</p>

<h2 id="prerequisites">Prerequisites</h2>
<ul>
  <li>Downloaded and Installed latest <a href="https://hortonworks.com/downloads/#sandbox">Hortonworks Sandbox</a></li>
  <li><a href="https://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a></li>
  <li>Allow yourself around one hour to complete this tutorial</li>
</ul>

<h2 id="outline">Outline</h2>
<ul>
  <li><a href="#hive">Hive</a></li>
  <li><a href="#hive-or-pig">Hive or Pig?</a></li>
  <li><a href="#our-data-processing-task">Our Data Processing Task</a></li>
  <li><a href="#download-the-data">Step 1: Download The Data</a></li>
  <li><a href="#upload-the-data-files">Step 2: Upload The Data Files</a></li>
  <li><a href="#start-the-hive-view">Step 3: Start the Hive View</a></li>
  <li><a href="#summary">Summary</a></li>
  <li><a href="#further-reading">Further Reading</a></li>
</ul>

<h2 id="hive-">Hive <a id="hive"></a></h2>

<p>Apache Hive is a component of <a href="https://hortonworks.com/hdp/">Hortonworks Data Platform</a>(HDP). Hive provides a SQL-like interface to data stored in HDP. In the previous tutorial, we used Pig, which is a scripting language with a focus on dataflows. Hive provides a database query interface to Apache Hadoop.</p>

<h2 id="hive-or-pig-">Hive or Pig? <a id="hive-or-pig"></a></h2>

<p>People often ask why do <a href="https://hortonworks.com/hadoop/pig/">Pig</a> and <a href="https://hortonworks.com/hadoop/hive/">Hive</a> exist when they seem to do much of the same thing. Hive because of its SQL like query language is often used as the interface to an Apache Hadoop based data warehouse. Hive is considered friendlier and more familiar to users who are used to using SQL for querying data. Pig fits in through its data flow strengths where it takes on the tasks of bringing data into Apache Hadoop and working with it to get it into the form for querying. A good overview of how this works is in Alan Gates posting on the Yahoo Developer blog titled <a href="http://yahoohadoop.tumblr.com/post/98256601751/pig-and-hive-at-yahoo">Pig and Hive at Yahoo!</a>. From a technical point of view, both Pig and Hive are feature complete, so you can do tasks in either tool. However, you will find one tool or the other will be preferred by the different groups that have to use Apache Hadoop. The good part is they have a choice and both tools work together.</p>

<h2 id="our-data-processing-task-">Our Data Processing Task <a id="our-data-processing-task"></a></h2>

<p>We are going to do the same data processing task as we just did with Pig in the previous tutorial. We have several files of truck driver statistics and we are going to bring them into Hive and do some simple computing with them. We are going to compute the sum of hours and miles logged driven by a truck driver for an year. Once we have the sum of hours and miles logged, we will extend the script to translate a driver id field into the name of the drivers by joining two different tables.</p>

<h2 id="step-1-download-the-data-">Step 1: Download The Data <a id="download-the-data"></a></h2>

<p>Download the driver data file from <a href="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/driver_data.zip">here</a>.
Once you have the file you will need to unzip the file into a directory. We will be uploading two csv files - <code class="highlighter-rouge">drivers.csv</code> and <code class="highlighter-rouge">timesheet.csv</code>.</p>

<h2 id="step-2-upload-the-data-files-">Step 2: Upload The Data Files <a id="upload-the-data-files"></a></h2>

<p>We start by selecting the <code class="highlighter-rouge">HDFS Files view</code> from the Off-canvas menu at the top. The HDFS Files view allows us to view the Hortonworks Data Platform(HDP) file store. This is separate from the local file system. For the Hortonworks Sandbox, it will be part of the file system in the Hortonworks Sandbox VM.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/select_files_view.png" alt="select_files_view" /></p>

<p>Navigate to <code class="highlighter-rouge">/user/maria_dev</code> and click on the <code class="highlighter-rouge">Upload</code> button to select the files we want to upload into the Hortonworks Sandbox environment.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/upload_button.png" alt="upload_button" /></p>

<p>Click on the <code class="highlighter-rouge">browse</code> button to open a dialog box. Navigate to where you stored the <code class="highlighter-rouge">drivers.csv</code> file on your local disk and select <code class="highlighter-rouge">drivers.csv</code> and click again <code class="highlighter-rouge">upload</code>. Do the same thing for <code class="highlighter-rouge">timesheet.csv</code>. When you are done you will see there are two new files in your directory.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/uploaded_files.png" alt="uploaded_files" /></p>

<h2 id="step-3-start-the-hive-view-">Step 3: Start the Hive View <a id="start-the-hive-view"></a></h2>

<p>Let’s open the <code class="highlighter-rouge">Hive View</code> by clicking on the Hive button in the top bar as previously when we selected the HDFS Files view. The Hive view provides a user interface to the Hive data warehouse system for Hadoop.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/select_hive_view.png" alt="select_hive_view" /></p>

<h3 id="31-explore-the-hive-user-interface">3.1 Explore The Hive User Interface</h3>

<p>On right is a <code class="highlighter-rouge">query editor</code>. A query may span multiple lines. At the bottom, there are buttons to <code class="highlighter-rouge">Execute</code> the query, <code class="highlighter-rouge">Explain</code> the query, <code class="highlighter-rouge">Save</code> the query with a name and to open a new Worksheet window for another query.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/hive_view_home_page.png" alt="hive_view_home_page" /></p>

<h4 id="hive-and-pig-data-model-differences">Hive and Pig Data Model Differences</h4>

<p>Before we get started let’s take a look at how <code class="highlighter-rouge">Pig and Hive</code> data models differ. In the case of Pig all data objects exist and are operated on in the script. Once the script is complete all data objects are deleted unless you stored them. In the case of Hive we are operating on the Apache Hadoop data store. Any query you make, table that you create, data that you copy persists from query to query. You can think of Hive as providing a data workbench where you can examine, modify and manipulate the data in Apache Hadoop. So when we perform our data processing task we will execute it one query or line at a time. Once a line successfully executes you can look at the data objects to verify if the last operation did what you expected. All your data is live, compared to Pig, where data objects only exist inside the script unless they are copied out to storage. This kind of flexibility is Hive’s strength. You can solve problems bit by bit and change your mind on what to do next depending on what you find.</p>

<h3 id="32-create-table-temp_drivers">3.2 Create Table temp_drivers</h3>

<p>The first task we will do is create a table to hold the data. We will type the query into the <code class="highlighter-rouge">composition area</code> on the right handside. Once you have typed in the query hit the <code class="highlighter-rouge">Execute</code> button at the bottom.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>create table temp_drivers (col_value STRING);
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/create_temp_drivers.png" alt="create_temp_drivers" /></p>

<blockquote>
  <p><strong>Hint:</strong> press <code class="highlighter-rouge">CTRL</code> + <code class="highlighter-rouge">Space</code> for autocompletion</p>
</blockquote>

<p>The query does not return any results because at this point we just created an empty table and we have not copied any data in it.
Once the query has executed we can refresh the <code class="highlighter-rouge">Database Explorer</code> at the left of the composition area and when folding down the default database we will see we have a new table called <code class="highlighter-rouge">temp_drivers</code>.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/database_explorer.png" alt="database_explorer" /></p>

<p>Clicking on the <code class="highlighter-rouge">icon</code> next to the table name a new Worksheets opens, which <code class="highlighter-rouge">loads</code> sample data from this table. We see the table is empty right now. This is a good example of the interactive feel you get with using Hive.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/sample_data_temp_drivers.png" alt="sample_data_temp_drivers" /></p>

<h3 id="33-create-query-to-populate-hive-table-temp_drivers-with-driverscsv-data">3.3 Create Query to Populate Hive Table temp_drivers with drivers.csv Data</h3>

<p>The next line of code will load the data file <code class="highlighter-rouge">drivers.csv</code> into the table <code class="highlighter-rouge">temp_drivers</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>LOAD DATA INPATH '/user/maria_dev/drivers.csv' OVERWRITE INTO TABLE temp_drivers;
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/load_data_temp_drivers.png" alt="load_data_temp_drivers" /></p>

<p>After executing the query we can look at the Tables again and when we browse the data for <code class="highlighter-rouge">temp_drivers</code> we see that the data has been read in. Note that Hive consumed the data file <code class="highlighter-rouge">drivers.csv</code> during this step. If you look in the <code class="highlighter-rouge">File Browser</code> you will see drivers.csv is no longer there.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/select_data_temp_drivers.png" alt="select_data_temp_drivers" /></p>

<h3 id="34-create-table-drivers">3.4 Create Table drivers</h3>

<p>Now that we have read the data in we can start working with it. The next thing we want to do extract the data. So first we will type in a query to create a new table called <code class="highlighter-rouge">drivers</code> to hold the data. That table will have six columns for <code class="highlighter-rouge">driverId, name, ssn, location, certified and the wage-plan</code> of drivers.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>CREATE TABLE drivers (driverId INT, name STRING, ssn BIGINT, location STRING, certified STRING, wageplan STRING);
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/create_table_drivers.png" alt="create_table_drivers" /></p>

<h3 id="35-create-query-to-extract-data-from-temp_drivers-and-store-it-to-drivers">3.5 Create Query to Extract Data from temp_drivers and Store It to drivers</h3>

<p>Then we extract the data we want from <code class="highlighter-rouge">temp_drivers</code> and copy it into <code class="highlighter-rouge">drivers</code>. We will do this with a <code class="highlighter-rouge">regexp</code> pattern. To do this we are going to build up a multi-line query. The six regexp_extract calls are going to extract the <code class="highlighter-rouge">driverId, name, ssn, location, certified and the wage-plan</code> fields from the table temp_drivers. When you are done typing the query it will look like this. Be careful as there are no spaces in the regular expression pattern.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>insert overwrite table drivers
SELECT
  regexp_extract(col_value, '^(?:([^,]*),?){1}', 1) driverId,
  regexp_extract(col_value, '^(?:([^,]*),?){2}', 1) name,
  regexp_extract(col_value, '^(?:([^,]*),?){3}', 1) ssn,
  regexp_extract(col_value, '^(?:([^,]*),?){4}', 1) location,
  regexp_extract(col_value, '^(?:([^,]*),?){5}', 1) certified,
  regexp_extract(col_value, '^(?:([^,]*),?){6}', 1) wageplan

from temp_drivers;
</code></pre>
</div>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/insert_into_drivers.png" alt="insert_into_drivers" /></p>

<p>Execute the query and look at the <code class="highlighter-rouge">drivers</code> table. You should see data that looks like this.</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/select_data_drivers.png" alt="select_data_drivers" /></p>

<h3 id="36-create-temp_timesheet-and-timesheet-tables-similarly">3.6 Create temp_timesheet and timesheet tables similarly</h3>

<p>Similarly, we have to create a table called <code class="highlighter-rouge">temp_timesheet</code>, then load the sample <code class="highlighter-rouge">timesheet.csv</code> file. Type the following queries one by one:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>CREATE TABLE temp_timesheet (col_value string);
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>LOAD DATA INPATH '/user/maria_dev/timesheet.csv' OVERWRITE INTO TABLE temp_timesheet;
</code></pre>
</div>

<p>You should see the data like this:</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/select_data_temp_timesheet.png" alt="select_data_temp_timesheet" /></p>

<p>Now create the table <code class="highlighter-rouge">timesheet</code> using the following query:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>CREATE TABLE timesheet (driverId INT, week INT, hours_logged INT , miles_logged INT);
</code></pre>
</div>

<p>Insert the data into the table <code class="highlighter-rouge">timesheet</code> from <code class="highlighter-rouge">temp_timesheet</code> table using the same <code class="highlighter-rouge">regexp_extract</code> as we did earlier.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>insert overwrite table timesheet
SELECT
  regexp_extract(col_value, '^(?:([^,]*),?){1}', 1) driverId,
  regexp_extract(col_value, '^(?:([^,]*),?){2}', 1) week,
  regexp_extract(col_value, '^(?:([^,]*),?){3}', 1) hours_logged,
  regexp_extract(col_value, '^(?:([^,]*),?){4}', 1) miles_logged

from temp_timesheet;
</code></pre>
</div>

<p>You should see the data like this:</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/select_data_timesheet.png" alt="select_data_timesheet" /></p>

<h3 id="37-create-query-to-filter-the-data-driverid-hours_logged-miles_logged">3.7 Create Query to Filter The Data (driverId, hours_logged, miles_logged)</h3>

<p>Now we have the data fields we want. The next step is to <code class="highlighter-rouge">group</code> the data by driverId so we can find the <code class="highlighter-rouge">sum</code> of hours and miles logged score for an year. This query first groups all the records by <code class="highlighter-rouge">driverId</code> and then selects the driver with the sum of the hours and miles logged runs for that year.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>SELECT driverId, sum(hours_logged), sum(miles_logged) FROM timesheet GROUP BY driverId;
</code></pre>
</div>

<p>The results of the query look like this:</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/group_data.png" alt="group_data" /></p>

<h3 id="38-create-query-to-join-the-data-driverid-name-hours_logged-miles_logged">3.8 Create Query to Join The Data (driverId, name, hours_logged, miles_logged)</h3>

<p>Now we need to go back and get the <code class="highlighter-rouge">driverId(s)</code> so we know who the driver(s) was. We can take the previous query and join it with the <code class="highlighter-rouge">drivers</code> records to get the final table which will have the <code class="highlighter-rouge">driverId, name and the sum of hours and miles logged</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>SELECT d.driverId, d.name, t.total_hours, t.total_miles from drivers d
JOIN (SELECT driverId, sum(hours_logged)total_hours, sum(miles_logged)total_miles FROM timesheet GROUP BY driverId ) t
ON (d.driverId = t.driverId);
</code></pre>
</div>

<p>The resulting data looks like:</p>

<p><img src="https://raw.githubusercontent.com/orendain/big-data-tutorials/master/tutorials/hdp/hdp-2.5/how-to-process-data-with-apache-hive/assets/join_data.png" alt="join_data" /></p>

<p>So now we have our results. As described earlier we solved this problem using Hive step by step. At any time we were free to look around at the data, decide we needed to do another task and come back. At all times the data is live and accessible to us.</p>

<h2 id="summary-">Summary <a id="summary"></a></h2>

<p>Congratulations on completing this tutorial! We just learned how to upload data into HDFS Files View and create hive queries to manipulate data. Let’s review all the queries that were utilized in this tutorial: <strong>create</strong>, <strong>load</strong>, <strong>insert</strong>, <strong>select</strong>, <strong>from</strong>, <strong>group by</strong>, <strong>join</strong> and <strong>on</strong>. With these queries, we created a table <em>temp_drivers</em> to store the data. We created another table <em>drivers</em>, so we can overwrite that table with extracted data from the <em>temp_drivers</em> table we created earlier. Then we did the same for <em>temp_timesheet</em> and <em>timesheet</em>.Finally, created queries to filter the data to have the result show the sum of hours and miles logged by each driver.</p>

<h2 id="further-reading-">Further Reading <a id="further-reading"></a></h2>
<ul>
  <li><a href="https://hortonworks.com/hadoop/hive/">Apache Hive</a></li>
  <li><a href="https://hortonworks.com/hadoop/hive/#tutorials">Hive Tutorials</a></li>
  <li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">Hive Language Manual</a></li>
</ul>

</div>

<hr>

<div id="tutorial-footer">
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>

  <p>If you need help or have questions with this tutorial, please check HCC for answers to existing questions about this tutorial by using the Find Answers button below.  You can post a new HCC question by using the Ask Questions button below.</p>

  <p>
    <a class="btn" href="https://community.hortonworks.com/topics/tutorial-110.html" role="button">Find Answers</a>
    <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-110&amp;topics=hdp-2.5.0" role="button">Ask Questions</a>
  </p>

  <p>Tutorial Name: <strong>How to Process Data with Apache Hive</strong></p>
  <p>HCC Tags:<strong> tutorial-110</strong> and <strong>hdp-2.5.0</strong></p>
  <p>If the tutorial has multiple components please indicate which one your question relates to.</p>

  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks GitHub repository and can be contributed to by following the <a href="https://github.com/hortonworks/big-data-tutorials/wiki">Tutorial Contribution Guide</a>.  For issues/bugs/feedback, please <a href="https://github.com/hortonworks/big-data-tutorials/issues/new">submit an issue</a> and we will do our best to resolve it!</p>
</div>

