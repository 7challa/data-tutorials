## Tutorial for Sandbox 2.0 version

### Introduction to Hunk Architecture

Hunk is a high performance, scalable software server written in Java, C/C++ and Python. Hunk works with machine data generated by any application, server or device. The Splunk Developer API is accessible via REST or the command line.

[![HunkArchitecture](http://hortonworks.com/wp-content/uploads/2013/11/HunkArchitecture.png)](http://hortonworks.com/wp-content/uploads/2013/11/HunkArchitecture.png)

After downloading, installing and starting Hunk, you’ll find two Hunk Server processes running on your host: splunkd and splunkweb.

*   **splunkd** is a distributed C/C++ server that accesses, processes and creates a virtual index from machine data and handles search requests. splunkd supports a command line interface for searching and viewing results.

*   **splunkweb** is a Python-based application server providing the Splunk Web user interface. It allows you to search and navigate machine data accessible by Hunk and to manage your Hunk deployment using your browser.

### Prerequisites:

1.  A virtual or physical 64-bit Linux operating system
2.  Install Java version 1.6 or later (v1.7 recommended)

### Get Started

1.  Download and install [Hortonworks Sandbox 2.0](http://hortonworks.com/products/hortonworks-sandbox/#install)
2.  Download Hunk – [download a 60 day free trial](http://www.splunk.com/download/hunk)
3.  Review the [tutorial](http://hortonworks.com/wp-content/uploads/2013/11/HDP_Sandbox_Tutorial_Splunk_2.0.pdf)

## Tutorial for Sandbox 1.3 version

### Prerequisites:

1.  A virtual or physical 64-bit Linux operating system
2.  Install Java version 1.6 or later (v1.7 recommended)

Note: this tutorial was validated with Sandbox 1.3

### Introduction

Deploying Hadoop ETL is easier than ever with DMX-h and the Hortonworks Sandbox. Watch this demo and experience for yourself how easy is to run ETL in your Hortonworks deployment. The Hadoop ETL demo will show you how to take advantage of the DMX-h graphical user interface to construct MapReduce jobs inside the Hortonworks Sandbox, inheriting the ease-of-use and performance of Syncsort’s high-performance ETL engine. Leverage existing ETL skills and start taking advantage of Apache Hadoop with the Hortonworks Sandbox and Syncsort DMX-h.

<iframe width="500" height="281" src="http://www.youtube.com/embed/ccisT2iGwh8?start=14&amp;feature=oembed" frameborder="0" allowfullscreen="" id="player0"></iframe>

### Get Started

1.  Watch the Demo Video above
2.  Get the [Hortonworks Sandbox](http://hortonworks.com/products/sandbox-instructions/)
3.  Get the download: [Syncsort DMX-h Test Drive](http://www.syncsort.com/en/Data-Integration/Registration/Hortonworks/Registration)

*   What’s Inside the Download:
    *   The test drive enables you to discover how our powerful, user-friendly ETL software delivers everything you need to turn Hadoop into a smarter Big Data solution.
    *   A fully-functional version of DMX-h for the Hortonworks Sandbox
    *   Templates & sample data for you to experiment with to implement a CDC Streaming test drive
    *   Installation instructions and documentation

### Get Started

1.  Download and install [Hortonworks Sandbox 1.3](http://hortonworks.com/products/hortonworks-sandbox/#install)
2.  Download Hunk – [download a 60 day free trial](http://www.splunk.com/download/hunk)
3.  Watch [video demo](http://www.youtube.com/watch?v=9zpKPivMkS0) of tutorial
4.  Review the [tutorial](http://hortonworks.com/wp-content/uploads/2013/11/HDP_Sandbox_Tutorial_Splunk_2.0.pdf)
