<div class="tutorial-content">
  <h1 id="how-to-use-hcatalog-pig--hive-commands">How to use HCatalog, Pig &amp; Hive Commands</h1>

<h2 id="introduction">Introduction</h2>

<p>In this tutorial, we will learn to use Hive and Pig along with other tools to process, analyze and filter large datasets.</p>

<h2 id="pre-requisites">Pre-Requisites</h2>

<ul>
  <li><a href="http://www.youtube.com/watch?v=_dVlNu4lqpE">Apache HCatalog Video (running time: about 9 minutes)</a></li>
  <li>Downloaded and Installed latest <a href="http://hortonworks.com/downloads/#sandbox">Hortonworks Sandbox</a></li>
  <li><a href="http://hortonworks.com/hadoop-tutorial/learning-the-ropes-of-the-hortonworks-sandbox/">Learning the Ropes of the Hortonworks Sandbox</a></li>
  <li>Allow yourself around one hour to complete this tutorial</li>
</ul>

<h2 id="outline">Outline</h2>
<ul>
  <li><a href="#download-example-data">Step 1: Download Example Data</a></li>
  <li><a href="#upload-data-files">Step 2: Upload the data files Into HDFS</a></li>
  <li>HDFS <a href="#further-reading-hdfs">Further Reading</a></li>
  <li><a href="#create-tables-data-hive-hcatalog">Step 3: Create tables for the Data With Hive and HCatalog</a></li>
  <li>HCatalog vs. Hive <a href="#further-reading-hcatalog-hive">Further Reading</a></li>
  <li><a href="#explore-hive-queries-view-structure-data">Step 4: Explore Hive Queries to View and Structure that Table Data</a></li>
  <li>Hive <a href="#further-reading-hive-query">Further Reading</a></li>
  <li><a href="#explore-pig-latin-data-transformation">Step 5: Explore Pig Latin Data Transformation</a></li>
  <li>Pig <a href="#further-reading-pig-latin">Further Reading</a></li>
</ul>

<h3 id="step-1-download-example-data-">Step 1: Download Example Data <a id="download-example-data"></a></h3>

<p>Download the <code class="highlighter-rouge">driver data</code> file from <a href="https://github.com/hortonworks/tutorials/blob/hdp-2.5/driver_data.zip">here</a>.
Once you have the file you will need to unzip the file into a directory. We will be uploading two csv files - <code class="highlighter-rouge">drivers.csv</code> and <code class="highlighter-rouge">truck_event_text_partition.csv</code>.</p>

<h3 id="step-2-upload-the-data-files-into-hdfs-">Step 2: Upload the data files Into HDFS <a id="upload-data-files"></a></h3>

<p>Start by using the <code class="highlighter-rouge">HDFS Files view</code> from the views drop down menu in Ambari:</p>

<p><img src="assets/select_files_view.png" alt="select_files_view" /></p>

<p>Navigate to the folder <code class="highlighter-rouge">/tmp</code> and create a new folder called <code class="highlighter-rouge">data</code>.</p>

<p><img src="assets/new_folder.png" alt="new_folder" /></p>

<p>Then use the menus to upload the <code class="highlighter-rouge">drivers.csv</code> file and <code class="highlighter-rouge">truck_event_text_partition.csv</code> file.</p>

<p><img src="assets/uploaded_files.png" alt="uploaded_files" /></p>

<p>After uploading both files head back to the data folder we created. Click on data row and select <code class="highlighter-rouge">Permissions</code>. Make sure all boxes are checked blue.</p>

<p><img src="assets/data_permissions.png" alt="data_permissions" /></p>

<p><img src="assets/edit_permissions.png" alt="edit_permissions" /></p>

<h2 id="further-reading-">Further Reading <a id="further-reading-hdfs"></a></h2>
<ul>
  <li><a href="http://hortonworks.com/hadoop/hdfs/#tutorials">HDFS Tutorials</a></li>
  <li><a href="http://hortonworks.com/hadoop/hdfs/">HDFS and Apache Hadoop</a></li>
  <li><a href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">HDFS Architecture Guide</a></li>
</ul>

<h3 id="step-3-create-tables-for-the-data-with-hive-and-hcatalog-">Step 3: Create tables for the Data With Hive and HCatalog <a id="create-tables-data-hive-hcatalog"></a></h3>

<p>HCatalog has been merged with Hive project. This means that your Hive queries will utilize HCatalog when using commands like create table and drop table.
We are now going to utilize the <code class="highlighter-rouge">Hive view</code> to create tables with our data. Use the same drop down menu that you used to select the HDFS Files view, and instead click <code class="highlighter-rouge">Hive View</code>.</p>

<p><img src="assets/select_hive_view.png" alt="select_hive_view" /></p>

<p>You will view a page like this:</p>

<p><img src="assets/hive_view_home_page.png" alt="hive_view_home_page" /></p>

<p>We’re now going to create a table from our CSV using a Hive query. Copy and paste the following query and click <code class="highlighter-rouge">Execute</code> to run the command and create the table.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>create table drivers
(driverId int,
 name string,
 ssn bigint,
 location string,
 certified string,
 wageplan string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
TBLPROPERTIES("skip.header.line.count"="1");
</code></pre>
</div>

<p><img src="assets/create_table_drivers.png" alt="create_table_drivers" /></p>

<p>You’ll now need to <code class="highlighter-rouge">load</code> the data file into the table. Use the following command to do so.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>LOAD DATA INPATH '/tmp/data/drivers.csv' OVERWRITE INTO TABLE drivers;
</code></pre>
</div>

<p><img src="assets/load_data_into_drivers.png" alt="load_data_into_drivers" /></p>

<p>You will see a new table <code class="highlighter-rouge">drivers</code> has been created and has all of the data contained within it. Click on the box next to the drivers table in <code class="highlighter-rouge">Database Explorer</code> to view the data.</p>

<p><img src="assets/select_driver_data.png" alt="select_driver_data" /></p>

<p>Repeat above steps for the second data set <code class="highlighter-rouge">truck_event_text_partition.csv</code> using the following queries to create the <code class="highlighter-rouge">truck_events</code> table.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>create table truck_events
(driverId int,
truckId int,
eventTime string,
eventType string,
longitude double,
latitude double,
eventKey string,
correlationId bigint,
driverName string,
routeId int,
routeName string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
STORED AS TEXTFILE
TBLPROPERTIES("skip.header.line.count"="1");
</code></pre>
</div>

<p><img src="assets/create_table_truck_events.png" alt="create_table_truck_events" /></p>

<p>Load the data by running the following command:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>LOAD DATA INPATH '/tmp/data/truck_event_text_partition.csv' OVERWRITE INTO TABLE truck_events;
</code></pre>
</div>

<p>You should now have two different tables inside the database explorer:</p>

<p><img src="assets/database_explorer.png" alt="database_explorer" /></p>

<p>You can view the data by clicking on the box next to the table truck_events.</p>

<p><img src="assets/select_truck_events_data.png" alt="select_truck_events_data" /></p>

<h2 id="further-reading--1">Further Reading <a id="further-reading-hcatalog-hive"></a></h2>

<ul>
  <li><a href="http://hortonworks.com/blog/hivehcatalog-data-geeks-big-data-glue/">Hive vs. HCatalog</a></li>
</ul>

<h3 id="step-4-explore-hive-queries-to-view-and-structure-that-table-data-">Step 4: Explore Hive Queries to View and Structure that Table Data <a id="explore-hive-queries-view-structure-data"></a></h3>

<p>In the previous sections you:</p>

<ul>
  <li>Uploaded your data file into HDFS</li>
  <li>Used the Ambari Hive view to create tables</li>
</ul>

<p>Apache Hive™ provides a data warehouse function to the Hadoop cluster. Through the use of HiveQL you can view your data as a table and create queries just as you would in a database.</p>

<p>To make it easy to interact with Hive, you can we can use Ambari’s built in views to run queries on this data.</p>

<p>In the latest versions of the Hortonworks sandbox we can <a href="http://hortonworks.com/blog/evaluating-hive-with-tez-as-a-fast-query-engine/">execute our Hive queries using Tez</a>, a fast execution engine. It improves on MapReduce in many areas and allows us near-realtime querying on our datasets in Hive.</p>

<p>Notice the query window and <strong>Execute</strong>. Type your queries in the Query window. When you are done with a query, click the <code class="highlighter-rouge">Execute</code>.</p>

<p>To see tables that Hive knows about, in Query Editor type the query:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>show tables
</code></pre>
</div>

<p>and click on <code class="highlighter-rouge">Execute</code>.</p>

<p><img src="assets/show_tables.png" alt="show_tables" /></p>

<p>Notice the tables that you previously created are in the list <strong>(“drivers” and “truck_events”)</strong>. You can see the columns in the table by executing:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>describe truck_events;
</code></pre>
</div>

<p><img src="assets/describe_truck_events.png" alt="describe_truck_events" /></p>

<p>You can make a join with other tables in Hive the same way you do with other database queries. Let’s make a join between <code class="highlighter-rouge">drivers</code> and <code class="highlighter-rouge">truck_events</code> tables.</p>

<p>Enter the following into the query editor:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>select a.driverId,a.driverName,a.eventType,b.certified
from truck_events a join drivers b ON (a.driverId = b.driverId);
</code></pre>
</div>

<p>This job is more complex so it might take longer than previous queries. You can watch the job running in the log. When the job completes, you can see the results.</p>

<p><img src="assets/join_data.png" alt="join_data" /></p>

<h2 id="further-reading--2">Further Reading <a id="further-reading-hive-query"></a></h2>
<ul>
  <li><a href="http://hortonworks.com/hadoop/hive/#tutorials">Hive Tutorials</a></li>
  <li><a href="http://hortonworks.com/hadoop/hive/">Apache Hive and Hadoop</a></li>
  <li><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">Getting Started with Hive</a></li>
</ul>

<h3 id="step-5-explore-pig-latin-data-transformation-">Step 5: Explore Pig Latin Data Transformation <a id="explore-pig-latin-data-transformation"></a></h3>

<p>In this tutorial, you will create and execute a <code class="highlighter-rouge">Pig script</code>. To access the Pig interface, use the dropdown menu for views in Ambari. Select <code class="highlighter-rouge">Pig View</code>.</p>

<p><img src="assets/select_pig_view.png" alt="select_pig_view" /></p>

<p>A special feature of the interface is the Pig helper. The Pig helper provides templates for the statements, functions, I/O statements, HCatLoader() and Python user defined functions. Another feature is the Pig arguments which provides pre-formatted command line arguments used during execution. You will see a page like this:</p>

<p><img src="assets/pig_view_home_page.png" alt="pig_view_home_page" /></p>

<p>Click <code class="highlighter-rouge">New Script</code> and create a name for it.</p>

<p><img src="assets/create_pig_script.png" alt="create_pig_script" /></p>

<p>In this section, you will load the data from the table that is stored in HCatalog/Hive. Then you will make a join between two data sets on the <code class="highlighter-rouge">driverId</code> field in the same way that you did in the Hive section.</p>

<h4 id="51-prepare-to-load-the-data">5.1 Prepare to load the data</h4>

<p>The data is already in HDFS through HCatalog. HCatalog stores schema and location information, so we can use the HCatLoader() function within the Pig script to read data from HCatalog-managed tables. In Pig, you now
only need to give the table a name or alias so that Pig can process the
table.</p>

<p>Follow this procedure to load the data using HCatLoader:</p>

<ul>
  <li>Use the right-hand pane to start adding your code at Line 1</li>
  <li>Open the Pig helper drop-down menu at the bottom of the screen to
give you a template for the line.</li>
</ul>

<p>Choose <strong>PIG helper -&gt; HCatalog -&gt; LOAD…</strong>template. This action
pastes the Load template into the script area.</p>

<p><strong>IMPORTANT</strong>! Note that the statement should be <code class="highlighter-rouge">org.apache.hive.hcatalog.pig.HCatLoader();</code>. Note the addition of the <strong>hive</strong> component.</p>

<p><img src="assets/pig_helper.png" alt="pig_helper" /></p>

<ul>
  <li>The entry <strong>%TABLE%</strong> is highlighted in red. Type the name of the
table (‘<strong>batting_data</strong>’) in place of <strong>%TABLE%</strong>(single quotes
are required).</li>
  <li>Remember to add the “a = “ before the template. This saves the
results into “a”.</li>
  <li>Make sure the statement ends with a semi-colon (;)</li>
</ul>

<p>Repeat this sequence for “truck_events” and add “ b = “</p>

<p>The completed lines of code will be:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>a = LOAD 'drivers' using org.apache.hive.hcatalog.pig.HCatLoader();
b = LOAD 'truck_events' using org.apache.hive.hcatalog.pig.HCatLoader();
</code></pre>
</div>

<p><img src="assets/load_data_into_pig.png" alt="load_data_into_pig" /></p>

<p>It is important to note that at this point, we have merely defined the aliases for our tables to hold the data (alias “a” for drivers and alias “b” for truck_events). Data is not loaded or transformed until we execute an operational command such as <code class="highlighter-rouge">DUMP</code> or <code class="highlighter-rouge">STORE</code></p>

<h4 id="52-join-both-the-tables-on-driverid">5.2 Join both the tables on driverId</h4>

<p>Next, you will use the <code class="highlighter-rouge">JOIN</code> operator to join both tables on the <code class="highlighter-rouge">driverid</code>. You will create a new data set using the Pig Join function that will match the driverid field and include all of the data from both tables.
Complete these steps:</p>

<ul>
  <li>Choose <strong>PIG helper-&gt;Data processing functions-&gt;JOIN template</strong></li>
  <li>Replace %VAR% with “a”. Repeat this step on the same line for “b”.</li>
  <li>Again, add the trailing semi-colon to the code.</li>
</ul>

<p>So, the final code will be:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>a = LOAD 'drivers' using org.apache.hive.hcatalog.pig.HCatLoader();
b = LOAD 'truck_events' using org.apache.hive.hcatalog.pig.HCatLoader();
c = join b by driverid, a by driverid;
</code></pre>
</div>

<p><img src="assets/join_data_in_pig.png" alt="join_data_in_pig" /></p>

<p>Now you have joined all the records in both of the tables on driverid.</p>

<h4 id="53-execute-the-script-and-generate-output">5.3 Execute the script and generate output</h4>

<p>To complete the Join operation, use the <code class="highlighter-rouge">DUMP</code> command to execute the results. This will show all of the records that have a common driverid. The data from both tables will be merged into one row. Complete this steps:</p>

<ul>
  <li>Add the last line with <strong>PIG helper-&gt;I/O-&gt;DUMP</strong> template and
replace %VAR% with “c”.</li>
</ul>

<p>The full script should be:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>a = LOAD 'drivers' using org.apache.hive.hcatalog.pig.HCatLoader();
b = LOAD 'truck_events' using org.apache.hive.hcatalog.pig.HCatLoader();
c = join b by driverid, a by driverid;
dump c;
</code></pre>
</div>

<p><img src="assets/dump_data_in_pig.png" alt="dump_data_in_pig" /></p>

<h4 id="54-save-the-script-and-execute-it">5.4 Save the script and execute it</h4>

<p>First you need to add the <code class="highlighter-rouge">-useHCatalog</code> (Case Sensitive) argument using the box box in the bottom right hand corner</p>

<p><img src="assets/use_hcatalog.png" alt="use_hcatalog" /></p>

<p>At the top of the screen, make sure the box “Execute on Tez” is checked. Then click <code class="highlighter-rouge">Execute</code> to run the script. This action creates one or more Tez jobs.</p>

<p>Below the <code class="highlighter-rouge">Execute</code> is a progress bar that shows the job’s status. The progress bar can be blue (indicating job is in process), red (job has a problem), or green (job is complete).</p>

<p><img src="assets/pig_script_running.png" alt="pig_script_running" /></p>

<p>When the job completes, you will see the results show up in one of the dropdown menus. The result is that each line that starts with an open parenthesis “(” has data from both tables for driverid.</p>

<p><img src="assets/join_results_in_pig.png" alt="join_results_in_pig" /></p>

<p>Click the <code class="highlighter-rouge">Logs</code> drop down menu if you want to see what happened when your script ran, including any error messages. (You might need to scroll down to view the entire log.)</p>

<p><img src="assets/join_logs_in_pig.png" alt="join_logs_in_pig" /></p>

<p>Congratulations! You have successfully completed HCatalog, Basic Pig &amp;
Hive Commands.</p>

<h2 id="further-reading--3">Further Reading <a id="further-reading-pig-latin"></a></h2>
<ul>
  <li><a href="http://hortonworks.com/hadoop/pig/#tutorials">Pig Tutorials</a></li>
  <li><a href="http://pig.apache.org/#Getting+Started">Getting Started with Pig</a></li>
</ul>

</div>

<div id="tutorial-footer">
  <hr>
  <h2>Tutorial Q&amp;A and Reporting Issues</h2>
  <p>If you need help or have questions with this tutorial, please first check HCC for existing Answers to questions on this tutorial using the Find Answers button.  If you don't find your answer you can post a new HCC question for this tutorial using the Ask Questions button.</p>
  <p><a class="btn" href="https://community.hortonworks.com/topics/tutorial-/tutorials/hortonworks/hdp-2.5/hcatalog-basic-pig-and-hive-commands-hdp2.5/tutorial.html" role="button">Find Answers</a> <a class="btn pull-right" href="https://community.hortonworks.com/questions/ask.html?space=81&topics=tutorial-hdp-2.5.0&topics=hdp-2.5.0" role="button">Ask Questions</a></p>
  <p>Tutorial Name: <strong>Using HCatalog, Pig, and Hive Commands</strong></p>
  <p>HCC Tutorial Tag:<strong> tutorial-/tutorials/hortonworks/hdp-2.5/hcatalog-basic-pig-and-hive-commands-hdp2.5/tutorial</strong> and <strong>hdp-2.5.0</strong></p>
  <p>If the tutorial has multiple labs please indicate which lab your question corresponds to. Please provide any feedback related to that lab.</p>
  <p>All Hortonworks, partner and community tutorials are posted in the Hortonworks github and can be contributed via the <a href="https://github.com/hortonworks/tutorials/wiki">Hortonworks Tutorial Contribution Guide</a>.  If you are certain there is an issue or bug with the tutorial, please <a href="https://github.com/hortonworks/tutorials/wiki#issues-with-tutorials">create an issue</a> on the repository and we will do our best to resolve it!</p>
</div>

